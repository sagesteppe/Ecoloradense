rm(template)
}
tiles <- file.path(pout, 'tilesPR', list.files(file.path(pout, 'tilesPR')))
pr_tile_path <- file.path(pout, paste0('pr_tiles', '_', resolution, iteration))
dir.create(pr_tile_path, showWarnings = F)
message('Writing Predicted Probability to Raster using tiles - this while take some time')
pb <- txtProgressBar(
min = 0,  max = length(tiles), style = 3, width = 50, char = "+")
for (i in seq_along(tiles)){
terra::predict(
rast(tiles[i]), rf_model, f = pr,
filename = file.path(pr_tile_path, paste0(i, '.tif')),
overwrite = T, na.rm=TRUE)
setTxtProgressBar(pb, i)
gc(verbose = FALSE)
}
close(pb)
mos <- terra::mosaic(sprc(
file.path(pr_tile_path, list.files(pr_tile_path))
), fun = 'mean')
writeRaster(
mos[[2]],
wopt = c(names = 'Probability'),
filename = file.path(pout, paste0(fname, '-Pr.tif')))
rm(mos)
unlink(file.path(pout, 'pr_tiles')) # can remove the tiles we used for the probability surface.
} else { # in these cases, we only need to use a single tile for prediction, we can
# just use the existing virtual raster to do this.
if(!file.exists(file.path(pout, paste0(fname, '-Pr.tif')))){
message('Writing Predicted Probability to Raster')
terra::predict( # rasters, skip straight to modelling.
cores = 1, f = pr,
rast_dat, rf_model, cpkgs = "ranger",
filename = file.path(pout, paste0(resolution, '-IterationCoarse', iteration, '.tif')),
wopt = c(names = 'predicted_suitability'), na.rm=TRUE,
overwrite = T)
writeRaster( # we wrote a raster with both predicted class probabilities onto it.
# we don't want both, we are going to 'rewrite' the raster so only one class remains.
rast(
file.path(
pout, paste0(resolution, '-IterationCoarse', iteration, '.tif')))[[2]],
file.path(pout, paste0(fname, '-Pr.tif')),
overwrite = T
)
file.remove(
file.path(
pout, paste0(resolution, '-IterationCoarse', iteration, '.tif')
)
)
} else {
'Predicted Probability Raster already exists - skipping.'}
}
unlink(file.path(pout, 'pr_tiles'))
gc(verbose = FALSE)
################ AREA OF APPLICABILITY SURFACE    ############################
message('Writing Area of Applicability to Raster')
AOAfun <- function(rf_model, r) {
CAST::aoa(r, model, LPD = FALSE, verbose=FALSE)$AOA
}
terra::predict( # rasters, skip straight to modelling.
cores = 1, f = AOAfun,
rast_dat, rf_model, cpkgs = "CAST",
filename = file.path(pout, paste0(fname, '-AOA', '.tif')),
wopt = c(names = 'AOA'), na.rm=TRUE,
overwrite = T)
###############      STANDARD ERROR PREDICTION        ########################
# the SE predictions are absurdly memory hungry, We will create 'tiles' to
# predict onto, and then combine them once the predictions are complete
# Note I use the term SE here, because it's what the R package uses, however,
# upon further reading what they are actually calculating is a Confidence
# interval - so great naming... https://github.com/imbs-hl/ranger/issues/136
if(se_prediction == TRUE){
tile_path_4se <- file.path(pout, paste0(resolution, 'TilesSE'))
final_se_path <- file.path(pout, paste0(resolution, 'SETiles'))
# it seems the tiles pretty much need to be under 200MB or so for safe CI prediction???
if(resolution == '3arc'){ntile = 2} else # 4 tiles
if(resolution == '1arc'){ntile = 6} else # 36 tiles Needed # earlier iteration with 16 FAILED # iter w/ 25 failed on tile 18...
if(resolution == '1-3arc'){ntile = 16}  # 144 /121/81 failed - follow under 200mb rule.
if(resolution == '3m'){
'Confidence Intervals cannot be produced for data of these size;
it would require over 2k tiles and 1 week of compute'}  else {
# don't create the tiles if they already exist.
if(exists(tile_path_4se)){
message('Tiles for SE exist at this resolution, skipping to predict.')} else {
message('Making tiles for prediction of standard errors')
dir.create(tile_path_4se, showWarnings = F)
dir.create(final_se_path, showWarnings = F)
template <- rast(nrows = ntile, ncols = ntile, extent = ext(rast_dat), crs = crs(rast_dat))
terra::makeTiles(rast_dat, template, filename = file.path(tile_path_4se, "tile_.tif"))
rm(template)
}
tiles <- file.path(tile_path_4se, list.files(tile_path_4se))
se <- function(...) predict(..., type = 'se', se.method = 'infjack',
predict.all = FALSE,
probability = TRUE, num.threads = cores/4)$se
# # predict the standard error onto the tiles.
# create and initialize progress bar
message('Predicting SE to tiles; this may take a really long time')
pb <- txtProgressBar(
min = 0,  max = length(tiles), style = 3, width = 50, char = "+")
for (i in seq_along(tiles)){
if(!file.exists(file.path(final_se_path, paste0('SE', i, '.tif')))){ # in case of crash, pick up where left off.
terra::predict(
rast(tiles[i]), rf_model, f = se,
filename = file.path(final_se_path, paste0('SE', i, '.tif')),
overwrite = T, na.rm=TRUE)
gc(verbose = FALSE)}
setTxtProgressBar(pb, i)
}
close(pb)
mos <- terra::mosaic(sprc(
file.path(final_se_path, list.files(final_se_path))
), fun = 'mean')
writeRaster(
mos[[2]],
wopt = c(names = 'standardError'),
filename = file.path(fname, '-SE.tif'),
overwrite = T)
gc(verbose = FALSE)
}
unlink(final_se_path)
}
}
distOrder_PAratio_simulator(
x = m30, distOrder = 0, PAratio = 4.5,
resolution = 90, iteration = 1, se_prediction = FALSE,
train_split = 0.9, p2proc = '../data/spatial/processed'
)
#' @param se_prediction boolean, whether to predict the SE surfaces or not, can add roughly
#' a week onto the prediction at 3m.
#' @param p2proc path to the processed raster data.
#' @param train_split Numeric. The proportion of data to use for train, at first iteration
#' a standard 0.8, good, but lot's of data are available for test later so up to 0.9 good.
#' @param PAratio Numeric. The ratio of presence to absences - simply for appending to file name,
#' the exact quantity are saved in model objects. "1:2"
#' @param distOrder Character. The distance between the nearest absence to presence, as a multiple of the cell resolution
#' e.g. distOrder 1 at a 90m resolution indicates the nearest absence is >90m away from a presence, at 10m it indicates > 10m away.
#'
modeller <- function(x, resolution, iteration, se_prediction, p2proc, train_split,
PAratio, distOrder){
if(missing(se_prediction)){se_prediction <- FALSE}
rast_dat <- rastReader(paste0('dem_', resolution), p2proc)
cores <- parallel::detectCores()
df <- dplyr::bind_cols(
dplyr::select(x, Occurrence),
dplyr::select(terra::extract(rast_dat, x), -ID),
) |>
tidyr::drop_na() %>%
dplyr::mutate(
Occurrence = as.factor(Occurrence)) |>
sf::st_drop_geometry()
fname <- paste0(resolution, '-Iteration', iteration, '-PA', PAratio, distOrder)
#######################         MODELLING           ##########################
# this is the fastest portion of this process. It will take at most a few minutes
# at any resolution, the goal of this paper wasn't really focused on comparing
# multiple models of families nor messing with parameters, so we use Random Forest
# simply because they work very well with default settings, almost 'controlling'
# for stochasticity in this portion of the work.
# only rerun modelling if a saved .rds object doesn't exist.
if(file.exists(paste0('../results/models/', fname, '.rds'))){
rf_model <- readRDS(paste0('../results/models/', fname, '.rds'))
message(
'An exising model for this resolution and iteration already exists;
reloading it now for projection')
} else {
# split the input data into both an explicit train and test data set.
TrainIndex <- caret::createDataPartition(
df$Occurrence, p = train_split, list = FALSE, times = 1)
Train <- df[TrainIndex,]; Test <- df[-TrainIndex,]
Train.sf <- sf::st_as_sf(Train, coords = c('Longitude', 'Latitude'), crs = 32613)
## remove totally uninformative features using Boruta analysis, these features
# can only hinder the model, and make prediction onto raster surfaces take longer
BorutaRes <- Boruta::Boruta(Occurrence ~ ., data = Train, num.threads = cores, doTrace = 1)
importance <- Boruta::attStats(BorutaRes)
rn <- rownames(importance)
important_vars <- Boruta::getSelectedAttributes(BorutaRes, withTentative = TRUE)
keep <- unique(c('Occurrence', important_vars))
Train <- Train[ , names(Train) %in% keep]
# develop a cross validation structure which is explicitly spatial
indices_knndm <- CAST::knndm(Train.sf, rast_dat, k=10)
# Use recursive feature elimination to find the optimal number and set of
# features.
ctrl <- caret::rfeControl(
functions = rfFuncs,
index = indices_knndm[["indx_train"]],
allowParallel = TRUE
)
rfProfile <- caret::rfe(
Train[,2:ncol(Train)],
Train$Occurrence,
rfeControl = ctrl,
metrics = yardstick::metric_set(yardstick::bal_accuracy)
)
rfP_tenth <- caret::pickSizeTolerance(rfProfile$results, metric = "Accuracy", tol = 0.1, maximize = TRUE)
v_tab <- rfProfile$variables
selected_vars <- v_tab[v_tab$Variables == rfP_tenth,] %>%
dplyr::group_by(var) %>%
dplyr::summarise(Overall_mean = mean(Overall)) %>%
dplyr::slice_max(Overall_mean, n = rfP_tenth) %>%
dplyr::pull(var)
Train <- Train[ , names(Train) %in% c('Occurrence', selected_vars)]
# Now we will tune the hyperparameters for this model.
tgrid <- expand.grid(
mtry =
floor(ncol(Train)/ 2.4):floor(ncol(Train)/ 1.6),
splitrule = 'gini',
min.node.size = c(1:9, seq(10, 30, by = 5))
)
# calculate class weights for the factor levels.
wts = c(
1 - sum(Train$Occurrence==0)/nrow(Train),
1 - sum(Train$Occurrence==1)/nrow(Train)
)
message('Tuning hyperparameters.')
model <- caret::train(
x = Train[,-grep('Occurrence', colnames(Train))],
y = Train$Occurrence,
method = "ranger",
num.trees = 750,
tuneGrid = tgrid,
metric = 'Accuracy',
keep.inbag = TRUE,
class.weights = wts,
importance = 'permutation',
trControl = caret::trainControl(
method="cv",
index = indices_knndm$indx_train,
savePredictions = "final",
allowParallel = TRUE)
)
rf_model <- ranger::ranger(
Occurrence ~ ., data = Train, probability = T, keep.inbag = TRUE,
mtry = model[['finalModel']][['mtry']],
min.node.size = model[['finalModel']][['min.node.size']],
importance = 'permutation',
class.weights = wts
)
# save the model
saveRDS(rf_model,
file = paste0('../results/models/', fname, '.rds'))
# save the test data.
write.csv(Test, paste0('../results/test_data/', fname, '.csv'))
# save the confusion matrix
predictions <- predict(rf_model, Test, type = 'se', se.method = 'infjack', probability=TRUE)
predictions$binary <- as.factor(if_else(predictions$predictions[,2] <= 0.49, 0, 1))
cmRestrat <- caret::confusionMatrix(predictions$binary, Test$Occurrence,
positive = '1', mode = 'everything')
saveRDS(cmRestrat,
file = paste0('../results/tables/', fname, '.rds'))
# we will also save the Pr-AUC as some folks find it a useful metric for class unbalanced
# data sets.
df_prauc <- data.frame(
truth = Test$Occurrence,
Class1 = predictions$predictions[,1]
)
yardstick::pr_auc(df_prauc, truth, Class1) |>
mutate(resolution = resolution, iteration = iteration) |>
write.csv(
paste0('../results/tables/', fname, '.csv'),
row.names = F)
rm(df, df_prauc, TrainIndex, Train, Test, predictions, cmRestrat)
}
pout <- '../results/suitability_maps'
###################      PREDICT ONTO SURFACE        #########################
# this prediction is generally straightforward, it doesn't take an obscene
# amount of RAM and can happen relatively quickly, just overnight for the
# higher resolution scenarios.
pr <- function(...) predict(..., type = 'response', num.threads = 1)$predictions
if(resolution %in% c('3arc', '1arc', '1-3arc', '3m')){ntile = 1} else
if(resolution == '1m'){ntile = 4}
if(ntile > 1){
tile_path_4pr <- file.path(pout, paste0('tilesPR', '_', resolution))
if(file.exists(tile_path_4pr)){
message('Tiles already created for this resolution, skipping to prediction!\n')
} else {
dir.create(tile_path_4pr, showWarnings = F); message('Making tiles for prediction')
template <- rast(nrows = ntile, ncols = ntile, extent = ext(rast_dat), crs = crs(rast_dat))
terra::makeTiles(rast_dat, template, filename = file.path(tile_path_4pr, "tile_.tif"))
rm(template)
}
tiles <- file.path(pout, 'tilesPR', list.files(file.path(pout, 'tilesPR')))
pr_tile_path <- file.path(pout, paste0('pr_tiles', '_', resolution, iteration))
dir.create(pr_tile_path, showWarnings = F)
message('Writing Predicted Probability to Raster using tiles - this while take some time')
pb <- txtProgressBar(
min = 0,  max = length(tiles), style = 3, width = 50, char = "+")
for (i in seq_along(tiles)){
terra::predict(
rast(tiles[i]), rf_model, f = pr,
filename = file.path(pr_tile_path, paste0(i, '.tif')),
overwrite = T, na.rm=TRUE)
setTxtProgressBar(pb, i)
gc(verbose = FALSE)
}
close(pb)
mos <- terra::mosaic(sprc(
file.path(pr_tile_path, list.files(pr_tile_path))
), fun = 'mean')
writeRaster(
mos[[2]],
wopt = c(names = 'Probability'),
filename = file.path(pout, paste0(fname, '-Pr.tif')))
rm(mos)
unlink(file.path(pout, 'pr_tiles')) # can remove the tiles we used for the probability surface.
} else { # in these cases, we only need to use a single tile for prediction, we can
# just use the existing virtual raster to do this.
if(!file.exists(file.path(pout, paste0(fname, '-Pr.tif')))){
message('Writing Predicted Probability to Raster')
terra::predict( # rasters, skip straight to modelling.
cores = 1, f = pr,
rast_dat, rf_model, cpkgs = "ranger",
filename = file.path(pout, paste0(resolution, '-IterationCoarse', iteration, '.tif')),
wopt = c(names = 'predicted_suitability'), na.rm=TRUE,
overwrite = T)
writeRaster( # we wrote a raster with both predicted class probabilities onto it.
# we don't want both, we are going to 'rewrite' the raster so only one class remains.
rast(
file.path(
pout, paste0(resolution, '-IterationCoarse', iteration, '.tif')))[[2]],
file.path(pout, paste0(fname, '-Pr.tif')),
overwrite = T
)
file.remove(
file.path(
pout, paste0(resolution, '-IterationCoarse', iteration, '.tif')
)
)
} else {
'Predicted Probability Raster already exists - skipping.'}
}
unlink(file.path(pout, 'pr_tiles'))
gc(verbose = FALSE)
################ AREA OF APPLICABILITY SURFACE    ############################
message('Writing Area of Applicability to Raster')
AOAfun <- function(rf_model, r) {
CAST::aoa(r, model, LPD = FALSE, verbose=FALSE)$AOA
}
terra::predict( # rasters, skip straight to modelling.
cores = 1, f = AOAfun,
rast_dat, rf_model, cpkgs = "CAST",
filename = file.path(pout, paste0(fname, '-AOA', '.tif')),
wopt = c(names = 'AOA'), na.rm=TRUE,
overwrite = T)
###############      STANDARD ERROR PREDICTION        ########################
# the SE predictions are absurdly memory hungry, We will create 'tiles' to
# predict onto, and then combine them once the predictions are complete
# Note I use the term SE here, because it's what the R package uses, however,
# upon further reading what they are actually calculating is a Confidence
# interval - so great naming... https://github.com/imbs-hl/ranger/issues/136
if(se_prediction == TRUE){
tile_path_4se <- file.path(pout, paste0(resolution, 'TilesSE'))
final_se_path <- file.path(pout, paste0(resolution, 'SETiles'))
# it seems the tiles pretty much need to be under 200MB or so for safe CI prediction???
if(resolution == '3arc'){ntile = 2} else # 4 tiles
if(resolution == '1arc'){ntile = 6} else # 36 tiles Needed # earlier iteration with 16 FAILED # iter w/ 25 failed on tile 18...
if(resolution == '1-3arc'){ntile = 16}  # 144 /121/81 failed - follow under 200mb rule.
if(resolution == '3m'){
'Confidence Intervals cannot be produced for data of these size;
it would require over 2k tiles and 1 week of compute'}  else {
# don't create the tiles if they already exist.
if(exists(tile_path_4se)){
message('Tiles for SE exist at this resolution, skipping to predict.')} else {
message('Making tiles for prediction of standard errors')
dir.create(tile_path_4se, showWarnings = F)
dir.create(final_se_path, showWarnings = F)
template <- rast(nrows = ntile, ncols = ntile, extent = ext(rast_dat), crs = crs(rast_dat))
terra::makeTiles(rast_dat, template, filename = file.path(tile_path_4se, "tile_.tif"))
rm(template)
}
tiles <- file.path(tile_path_4se, list.files(tile_path_4se))
se <- function(...) predict(..., type = 'se', se.method = 'infjack',
predict.all = FALSE,
probability = TRUE, num.threads = cores/4)$se
# # predict the standard error onto the tiles.
# create and initialize progress bar
message('Predicting SE to tiles; this may take a really long time')
pb <- txtProgressBar(
min = 0,  max = length(tiles), style = 3, width = 50, char = "+")
for (i in seq_along(tiles)){
if(!file.exists(file.path(final_se_path, paste0('SE', i, '.tif')))){ # in case of crash, pick up where left off.
terra::predict(
rast(tiles[i]), rf_model, f = se,
filename = file.path(final_se_path, paste0('SE', i, '.tif')),
overwrite = T, na.rm=TRUE)
gc(verbose = FALSE)}
setTxtProgressBar(pb, i)
}
close(pb)
mos <- terra::mosaic(sprc(
file.path(final_se_path, list.files(final_se_path))
), fun = 'mean')
writeRaster(
mos[[2]],
wopt = c(names = 'standardError'),
filename = file.path(fname, '-SE.tif'),
overwrite = T)
gc(verbose = FALSE)
}
unlink(final_se_path)
}
}
distOrder_PAratio_simulator(
x = m30, distOrder = 0, PAratio = 4.5,
resolution = 90, iteration = 1, se_prediction = FALSE,
train_split = 0.9, p2proc = '../data/spatial/processed'
)
library(sf)
library(tidyverse)
library(terra)
library(caret)
library(bonsai)
library(parsnip)
library(lightgbm)
library(future)
library(dials)
library(finetune)
source('functions.R')
set.seed(23)
p <- '../data/Data4modelling'
f <- file.path(p, list.files(p))
abs <- st_read('../data/Data4modelling/iter1-pa.gpkg')
m30 <- sf::st_read("../data/Data4modelling/90m-presence-iter1.gpkg") %>%
rename(Occurrence = Presenc) |>
sf::st_as_sf()
### we know that 1:1 absence to presence is far too low when including the 'local'
# absences.
m30 <- bind_rows(m30, abs)
m30 <- filter(m30, st_is(m30, "POINT")) |>
select(Occurrence)
distOrder_PAratio_simulator(
x = m30, distOrder = 0, PAratio = 4.5,
resolution = 90, iteration = 1, se_prediction = FALSE,
train_split = 0.9, p2proc = '../data/spatial/processed'
)
`3arc-Iteration1-PA1:4.5DO:0` <- readRDS("/media/steppe/hdd/EriogonumColoradenseTaxonomy/results/tables/3arc-Iteration1-PA1:4.5DO:0.rds")
View(`3arc-Iteration1-PA1:4.5DO:0`)
`3arc-Iteration1-PA1:4.5DO:0`[["overall"]]
`3arc-Iteration1-PA1:4.5DO:0`[["byClass"]]
`3arc-Iteration1-PA1:4.2DO:0` <- readRDS("/media/steppe/hdd/EriogonumColoradenseTaxonomy/results/tables/3arc-Iteration1-PA1:4.2DO:0.rds")
View(`3arc-Iteration1-PA1:4.2DO:0`)
`3arc-Iteration1-PA1:4.2DO:0`[["byClass"]]
library(sf)
library(tidyverse)
library(terra)
library(caret)
library(bonsai)
library(parsnip)
library(lightgbm)
library(future)
library(dials)
library(finetune)
source('functions.R')
set.seed(23)
p <- '../data/Data4modelling'
f <- file.path(p, list.files(p))
abs <- st_read('../data/Data4modelling/iter1-pa.gpkg')
m30 <- sf::st_read("../data/Data4modelling/30m-presence-iter1.gpkg") %>%
rename(Occurrence = Presenc) |>
sf::st_as_sf()
### we know that 1:1 absence to presence is far too low when including the 'local'
# absences.
m30 <- bind_rows(m30, abs)
m30 <- filter(m30, st_is(m30, "POINT")) |>
select(Occurrence)
distOrder_PAratio_simulator(
x = m30, distOrder = 0, PAratio = 3.0,
resolution = 30, iteration = 1, se_prediction = FALSE,
train_split = 0.9, p2proc = '../data/spatial/processed'
)
abs <- st_read('../data/Data4modelling/iter1-pa.gpkg')
m30 <- sf::st_read("../data/Data4modelling/10m-presence-iter1.gpkg") %>%
rename(Occurrence = Presenc) |>
sf::st_as_sf()
### we know that 1:1 absence to presence is far too low when including the 'local'
# absences.
m30 <- bind_rows(m30, abs)
m30 <- filter(m30, st_is(m30, "POINT")) |>
select(Occurrence)
distOrder_PAratio_simulator(
x = m30, distOrder = 0, PAratio = 2.7,
resolution = 10, iteration = 1, se_prediction = FALSE,
train_split = 0.9, p2proc = '../data/spatial/processed'
)
gc()
library(sf)
library(tidyverse)
library(terra)
library(caret)
library(bonsai)
library(parsnip)
library(lightgbm)
library(future)
library(dials)
library(finetune)
source('functions.R')
set.seed(23)
p <- '../data/Data4modelling'
f <- file.path(p, list.files(p))
abs <- st_read('../data/Data4modelling/iter1-pa.gpkg')
m30 <- sf::st_read("../data/Data4modelling/10m-presence-iter1.gpkg") %>%
rename(Occurrence = Presenc) |>
sf::st_as_sf()
### we know that 1:1 absence to presence is far too low when including the 'local'
# absences.
m30 <- bind_rows(m30, abs)
m30 <- filter(m30, st_is(m30, "POINT")) |>
select(Occurrence)
distOrder_PAratio_simulator(
x = m30, distOrder = 0, PAratio = 3.0,
resolution = 10, iteration = 1, se_prediction = FALSE,
train_split = 0.9, p2proc = '../data/spatial/processed'
)
