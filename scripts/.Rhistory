geom_point() +
facet_grid(. ~ name, scales = 'free')
ggplot(scout_long, aes(y = POP_CENSUS_LOG, x = value)) +
geom_point() +
facet_grid(. ~ name, scales = 'free')
ggplot(scout_long, aes(y = POP_CENSUS_LOG, x = value)) +
geom_point() +
geom_line()
ggplot(scout_long, aes(y = POP_CENSUS_LOG, x = value)) +
geom_point() +
geom_abline()
ggplot(scout_long, aes(y = POP_CENSUS_LOG, x = value)) +
geom_point() +
geom_smooth()
ggplot(scout_long, aes(y = POP_CENSUS_LOG, x = value)) +
geom_point() +
geom_smooth() +
facet_grid(. ~ name, scales = 'free')
ggplot(scout_long, aes(y = POP_CENSUS_LOG, x = value)) +
geom_point() +
facet_grid(. ~ name, scales = 'free') +
geom_smooth()
ggplot(scout_long, aes(y = POP_CENSUS_LOG, x = value)) +
geom_point() +
facet_grid(. ~ name, scales = 'free') +
geom_smooth(aes(group=name))
write.csv(scout_long, '../data/SOS/LandscapeMetrics.csv')
library(tidyverse)
library(sf)
library(terra)
scouting <- read.csv('../data/SOS/Scouting.csv') |>
mutate(taxa = gsub(' ', '_', taxa)) |>
select(c(1:10, 22, 23)) |>
filter(taxa != 'Achnatherum_hymenoides')
f <- list.files('../results/suitability_maps')
f <- f[ str_detect(f, '1k')]
f <- data.frame(
f_suitability = paste0('../results/suitability_maps/', f),
species = gsub('1k-.*', '', f)
)
scouting <- filter(scouting, taxa %in% f$species) |>
sf::st_as_sf(coords = c('LONGITUDE_DECIMAL', 'LATITUDE_DECIMAL'), crs = 4326) |>
st_transform(5070)
# here are the ranked patches
f_rp <- list.files('../results/rankedPatches-manuscript', pattern = '.shp')
f_rp <- data.frame(
f_rankedp = paste0('../results/rankedPatches-manuscript/', f_rp),
species = gsub('[.]shp$', '', f_rp)
)
f_pm <- list.files('../results/patch_metrics')
f_pm <- data.frame(
f_patchMetrics = paste0('../results/patch_metrics/', f_pm[grepl('patch', f_pm)]),
f_classMetrics = paste0('../results/patch_metrics/', f_pm[grepl('class', f_pm)])
) |>
mutate(species = gsub('-.*$', '', basename(f_patchMetrics)))
files <- left_join(f, f_rp, by = 'species') |>
left_join(f_pm, by = 'species') |>
relocate(species, .before = 1) |>
filter(species %in% scouting$taxa)
rm(f, f_rp, f_pm)
scouting <- left_join(scouting, files, by = c('taxa' = 'species')) |>
mutate(Presence = if_else(POPULATION_SIZE > 0, 1, 0), .after = POPULATION_SIZE) |>
# penstemon palmeri are all seeded outside their native range and 'helped' along
# during establishment we will remove them from the analysis
filter(taxa != 'Penstemon_palmeri')
scout_split <- split(scouting, scouting$taxa)
# we are going to discard species with fewer than 3 observations.
scout_split <- scout_split[lapply(scout_split, nrow) >= 3]
#' return predicted suitability scores and patch ID's for scouting points
#'
#' Use this function to return some modeled values from scouting points observations
#' @param x an sf/tibble/data frame split by species, and including columns with
#' paths to required files.
extractR <- function(x){
suitability <- terra::rast(sf::st_drop_geometry(x$f_suitability[1]))
patch_ranks <- sf::st_read(sf::st_drop_geometry(x$f_rankedp[1]), quiet = T)
x <- sf::st_join(x, patch_ranks)
suitability <- terra::extract(suitability, x)$predicted_suitability
# now we can join the class and patch metrics to each population
# which they were calculated for.
IDs <- tidyr::drop_na(x, PchIDComb) |>
dplyr::pull(PchIDComb)
patch <- read.csv(sf::st_drop_geometry(x$f_patchMetrics[1]) ) |>
dplyr::filter(id %in% IDs) |>
tidyr::pivot_wider(values_from = value, names_from = metric)
class <- read.csv(sf::st_drop_geometry(x$f_classMetrics[1])) |>
tidyr::pivot_wider(names_from = metric, values_from = value)
if(nrow(patch) == 0){
patch <- data.frame(id = NA, cai = NA, enn = NA, frac = NA, para = NA )
}
lsm <- cbind(patch, class) |>
dplyr::mutate(id = as.character(id))
wide <- dplyr::mutate(
x,
suitability = suitability,
.before = geometry) |>
dplyr::select(-f_patchMetrics, -f_classMetrics) |>
dplyr::left_join(lsm, by = c('PchIDComb' = 'id' ))
return(wide)
}
scouting <- lapply(scout_split, extractR)
scouting <- dplyr::bind_rows(scouting)
# for manuscript 193 records are NA.
p <- '../data/raw/occurrence/combined_records'
f <- file.path(p, list.files(p, pattern = '.shp$'))
f_occ <- data.frame(
f_occ = f,
taxa = gsub('[.]shp$', '', basename(f))
)
files <- left_join(scouting, f_occ, by = 'taxa')
f <- split(files, f = files$f_rankedp)
strip_occurrences <- function(x){
occurrences <- sf::st_read(sf::st_drop_geometry(x$f_occ[1]), quiet = T) |>
sf::st_buffer(1000)
ints <- sf::st_intersects(occurrences, x) # identify intersecting points
removals <- unique(unlist(ints[lengths(ints) > 0])) # remove them.
if(length(removals > 0)){
x <- x[-removals,]
}
return(dplyr::select(x, -f_occ))
}
files <- lapply(f, strip_occurrences) |>
bind_rows()
rm(f, p, strip_occurrences)
suitability_amounts <- readRDS('../data/processed/prcntSDMsurfaceSuitable.rds') |>
bind_rows()
prctn <- split(suitability_amounts, f = suitability_amounts$Percent)
suitability_means <- lapply(prctn, \(x)
data.frame(as.list(
elucidate::mean_ci(x$Records, replicates = 1000, ci_level = 0.99))
)
) |>
bind_rows() |>
mutate(Percent = 1:100)
#################################################################################
fp <- scouting[scouting$futurePotential=='Yes',]
fp <- arrange(fp, suitability) |>
st_drop_geometry() |>
select(suitability) |>
mutate(obs = 1:n() / n())
### Here we prep some display text which will help users interpret the plot ####
################################################################################
sm50 <- suitability_means[ which.min(abs(suitability_means$Percent-50)), ]
# on average 50% of cells have lower probabilities of being suitable than 0.23
sm80 <- suitability_means[ which.min(abs(suitability_means$Percent-80)), ]
# on average 80% of cells have lower probabilities of being suitable than 0.614
fp_2 <- fp[ which.min(abs(fp$obs-0.2)), ] # 80% of all populations are found in areas with suitability > 65.2%
fp_5 <- fp[ which.min(abs(fp$obs-0.5)), ] # 50% of all populations are found in areas with suitability > 83.6%
fp_8 <- fp[ which.min(abs(fp$obs-0.8)), ] # the final 20 % of populations are found in areas with suitability > 94.6%
labs <- data.frame(
x = c(
round(fp_2$obs, 2)*100 -10,
round(fp_5$obs, 2)*100 - 10,
sm50$Percent+15,
sm80$Percent+15),
y = c(
round(fp_2$suitability, 2) + 0.1,
round(fp_5$suitability, 2) + 0.1,
sm50$mean - 0.15,
sm80$mean - 0.15),
label = c(
paste0(100- (round(fp_2$obs, 2)*100), '% of pops.\nwere found in areas\nwith suitability > ', round(fp_2$suitability, 2)),
paste0(round(fp_5$obs, 2)*100, '% of pops.\nwere found in areas\nwith suitability > ', round(fp_5$suitability, 2)),
paste0(sm50$Percent, '% of cells have\nprobabilities of being\nsuitable lower than ', round(sm50$mean, 2)),
paste0(sm80$Percent, '% of cells have\nprobabilities of being\nsuitable lower than ', round(sm80$mean, 2))
)
)
################################################################################
# Create the mean suitability values across all taxa, this will illustrate the
# distribution of modeled suitable habitat across 'common species' in the West based
# on our input data and modelling approach.
suitability_means <- suitability_means |>
mutate(Null_mod = mean*Percent)
## create a dummy species var to put the grey50 color on the legend.
dum_species <- data.frame(Percent = 1, Records = 0.1, Species = 'dum')
linecols <- c( # define our palette
'Species' = 'grey50',
"Mean (95% CI)" = "#093824",
"95% CI" = "#73BA9B",
"Observed Populations" = "#7570b3",
'Theoretical Probability' = '#d95f02'
)
ggplot(suitability_amounts,
aes(x = Percent, y = Records, color = Species, group = Species)) +
geom_line(lty = 1) +
scale_color_grey(guide = 'none') +
ggnewscale::new_scale_color() +
geom_ribbon(data = suitability_means, aes(ymin = lower, ymax = upper, x = Percent, fill = '95% CI'),
inherit.aes = F, alpha = 0.5) +
geom_line(data = suitability_means,
aes(x = Percent, y =  mean, color = 'Mean (95% CI)'),
inherit.aes = F, lwd = 1) +
geom_line(data = suitability_means, aes(y = Percent/100, x = Null_mod, color = 'Theoretical Probability'),
inherit.aes = F, lwd = 1) +
geom_line(data = fp, aes(y = suitability, x = obs*100, color = 'Observed Populations'), inherit.aes = F, lwd = 1) +
geom_line(data = dum_species, aes(color = 'Species'), lwd = 1) +
labs(
title = 'Populations are found in areas\nwith higher predicted suitability',
x = "Raster Cells (cumulative)",
y = 'Predicted Suitability') +
theme_classic() +
scale_y_continuous(
breaks = seq(0, 1, by = 0.2)
)  +
scale_fill_manual(values = linecols, guide = 'none') +
scale_colour_manual(
values = linecols, name = NULL,
breaks = c('Species', 'Mean (95% CI)', 'Theoretical Probability', 'Observed Populations')) +
scale_x_continuous(
breaks = seq(0, 100, by = 20), labels = \(x) paste0(x, "%"),
sec.axis = sec_axis(~., name = 'Populations Found (cumulative)',
breaks = seq(0, 100, by = 20), labels = \(x) paste0(x, "%"))) +
theme(
legend.position=c(.9,.10),
plot.title = element_text(hjust = 0.5),
aspect.ratio = 1/1) +
geom_segment(
aes(
xend = fp_2$obs*100,
yend = fp_2$suitability,
x = round(fp_2$obs, 2)*100 - 10,
y = fp_2$suitability + 0.1),
arrow = arrow(length = unit(0.25, "cm")), color = 'black') +
geom_segment(
aes(
xend = fp_5$obs*100,
yend = fp_5$suitability,
x = round(fp_5$obs, 2)*100 - 10,
y = fp_5$suitability + 0.1),
arrow = arrow(length = unit(0.25, "cm")), color = 'black') +
geom_segment(aes(xend = sm50$Percent, yend = sm50$mean,
x = sm50$Percent+15, y = sm50$mean - 0.15),
arrow = arrow(length = unit(0.25, "cm")), color = 'black') +
geom_segment(aes(xend = sm80$Percent, yend = sm80$mean,
x = sm80$Percent+15, y = sm80$mean - 0.15),
arrow = arrow(length = unit(0.25, "cm")), color = 'black') +
geom_label(data = labs, aes(x = x, y = y, label = label),
inherit.aes = F, size = 3 ,
######        USE THIS TO MAKE THE PLOT TRANSPARENT FOR THE TALK        #####
fill='transparent', color = 'white') +
theme(
axis.text = element_text(color = 'white'),
axis.ticks = element_line(color = 'white'),
panel.background = element_rect(fill='transparent'), #transparent panel bg
plot.background = element_rect(fill='transparent', color=NA), #transparent plot bg
panel.grid.major = element_blank(), #remove major gridlines
panel.grid.minor = element_blank(), #remove minor gridlines
legend.background = element_rect(fill='transparent'), #transparent legend bg
legend.box.background = element_rect(fill='transparent'), #transparent legend panel
text = element_text(colour = "white")
)
ggsave('../plots/leafplot-trans.png', width = 9, height = 9, units = 'in')
rm(fp, fp_2, fp_5, fp_8, labs, prctn, sm50, sm80, linecols)
fp <- scouting[scouting$futurePotential=='Yes',]
quants <- quantile(fp$suitability, na.rm = TRUE, probs = c(0.25, 0.5, 0.75))
hist(fp$suitability)
abline(v = quants[[1]], lwd = 2)
abline(v = quants[[2]], lwd = 2)
hist(fp$Rank)
scout1 <- mutate(
scout1,
taxa = as.factor(taxa),
COLL_ID = as.factor(COLL_ID))
scout_long |>
sf::st_drop_geometry() |>
write.csv('../data/SOS/LandscapeMetrics.csv', row.names  = F)
scout_long <- pivot_longer(scouting, cai:enn_mn)
scout_long <- mutate(
scout_long,
POP_CENSUS_SQRT = sqrt(POPULATION_SIZE),
POP_CENSUS_LOG = log(POPULATION_SIZE)
)
scout_long |>
sf::st_drop_geometry() |>
write.csv('../data/SOS/LandscapeMetrics.csv', row.names  = F)
id <- Sys.getenv("CDSE_ID")
secret <- Sys.getenv("CDSE_SECRET")
OAuthClient <- GetOAuthClient(id = id, secret = secret)
library(CDSE)
dsn <- system.file("extdata", "luxembourg.geojson", package = "CDSE")
aoi <- sf::read_sf(dsn, as_tibble = FALSE)
images <- SearchCatalog(aoi = aoi, from = "2023-07-01", to = "2023-07-31",
collection = "sentinel-2-l2a", with_geometry = TRUE, client = OAuthClient)
OAuthClient <- GetOAuthClient(id = id, secret = secret)
day <- images[order(images$tileCloudCover), ]$acquisitionDate[1]
library(CDSE)
SearchCatalogByTimerange
?SearchCatalogByTimerange
Sys.getenv('CopernicusOAuthIDNORTHWESTERN')
library(CDSE)
library(terra)
library(sf)
library(tidyverse)
library(sf)
library(terra)
setwd('/media/steppe/hdd/EriogonumColoradenseTaxonomy/scripts')
# first we will create a domain for all analysis. The 'closest' this bounding box is to a known
# occurrence is 10 miles. The furthest distances vary.
domain <- sf::st_read('../data/collections/occurrences_coloradense/occurrences.shp', quiet = T) %>%
st_union() %>%
st_transform(32613) %>%
st_buffer(16093) %>%
st_transform(4326) %>%
vect()
ext(domain)
template <- rast(project(domain, 'EPSG:32613'), nrows = 5, ncols = 5)
# now we will assemble single DEM tifs which cover our domain
OAuthClient <- GetOAuthClient(
id = Sys.getenv("CopernicusOAuthIDNORTHWESTERN"),
secret = Sys.getenv("CopernicusOAuthSecretNORTHWESTERN")
)
script_file <- '/media/steppe/hdd/EriogonumColoradenseTaxonomy/scripts/NDSI_download.js'
aoi <- st_as_sfc(st_bbox(template))
catalog_results <- SearchCatalog(
aoi = aoi,
from = as.Date('2017-05-01'), to = as.Date('2024-08-01'),
# first relevant flights are in 2017, a was flying in 2016,
# but we'll just skip that year to make writing methods easier
collection = "sentinel-2-l2a",
client = OAuthClient
)
cr <- catalog_results |>
mutate(Month = as.numeric(str_remove_all(str_extract(acquisitionDate, '-[0-9]{2}-'), '-'))) |>
filter(Month >= 5, Month <= 7) |> # we want to detect late laying snow packs
group_by(acquisitionDate) |>
# only bother with tiles which have good coverage on that day! No need for random tiles.
mutate(
totalArea = sum(areaCoverage),
n = n()) |>
filter(n > 4 & totalArea >= 100) |>
# NDSI cannot see through clouds, we will drop dates with
# very high cloud cover
group_by(acquisitionDate) |>
mutate(
meanCloud = mean(tileCloudCover)
) |>
filter(meanCloud <= 40) |>
# for visualizing whether we have an OK cloud drop off time
mutate(
year = str_extract(acquisitionDate, '[0-9]{4}'),
doy = yday(acquisitionDate)
)
script_file <- '/media/steppe/hdd/EriogonumColoradenseTaxonomy/scripts/NDSI_download.js'
aoi <- st_as_sfc(st_bbox(template))
catalog_results <- SearchCatalog(
aoi = aoi,
from = as.Date('2017-05-01'), to = as.Date('2024-08-01'),
# first relevant flights are in 2017, a was flying in 2016,
# but we'll just skip that year to make writing methods easier
collection = "sentinel-2-l2a",
client = OAuthClient
)
Sys.getenv("CopernicusOAuthSecretNORTHWESTERN")
Sys.getenv("CopernicusOAuthSecretNORTHWESTERN")
library(sf)
library(tidyverse)
library(terra)
source('functions.R')
set.seed(23)
ground_truth <- read.csv('../data/GroundTruthing/Pts.csv') |>
mutate(
across(c('Dominant_Phen'), ~ na_if(., '')),
across(Presence_M:Presence_J, ~ replace_na(., 0)))
rand_pts_iter1 <- st_read('../data/GroundTruthPts/Iteration1-cp.shp', quiet = T) |>
select(UID) %>%
inner_join(., ground_truth, by = c('UID' = 'GlobalRandomID')) |>
mutate(Site = paste0('r-', UID)) |>
select(-Latitude, -Longitude, -UID)
ground_truth <- filter(ground_truth, is.na(GlobalRandomID)) # remove these random pts
revisits <- st_read('../data/GroundTruthPts/Revisits-cp.shp', quiet = T) |>
select(UID) |>
mutate(UID = str_replace(UID, 'P', 'p')) %>%
inner_join(., filter(ground_truth, str_detect(Site, 'p')), by = c('UID' = 'Site'))
ground_truth <- filter(ground_truth, str_detect(Site, 'p', negate= T)) |>
select(-GlobalRandomID) |>
st_as_sf(coords = c(x = 'Longitude', y = 'Latitude'), crs = 4269) |>
st_transform(st_crs(revisits))
revisits <- filter(revisits, !is.na(Latitude)) |>
st_drop_geometry() |>
st_as_sf(coords = c(x = 'Longitude', y = 'Latitude'), crs = 4269) |>
st_transform(st_crs(revisits)) %>%
bind_rows(., filter(revisits, is.na(Latitude))) |>
mutate(Site = UID) |>
select(-Latitude, -Longitude, -UID)
ground_truth <- bind_rows(ground_truth, rand_pts_iter1, revisits) |>
select(-GlobalRandomID) %>%
mutate(Presence = ifelse(Presence_M > 0 | Presence_J > 0, 1, 0), .after = Presence_J)
st_write(ground_truth, '../data/GroundTruthing/QC.shp', append = F)
rm(rand_pts_iter1, revisits)
gt_pres <- filter(ground_truth, Presence == 1) |>
dplyr::select(NAME = OBJECT) |>
sf::st_write(dsn = '../data/GroundTruthing/Presences.kml', driver = 'kml',
quiet = T, append = F)
gt_abs <- filter(ground_truth, Presence == 0) |>
dplyr::select(NAME = OBJECT) |>
sf::st_write(dsn = '../data/GroundTruthing/Absences.kml', driver = 'kml',
quiet = T, append = F)
comp_abs <- read.csv('../data/GroundTruthing/ComputerAbs.csv') |>
mutate(Presence_M = 0, Presence_J = 0, Presence = 0) |>
st_as_sf(coords = c(x = 'Longitude', y = 'Latitude'), crs = 4326) |>
st_transform(st_crs(ground_truth))
ab <- bind_rows(ground_truth, comp_abs) |>
st_write('../data/GroundTruthing/Iteration1Pts.shp', append = F)
library(spdep)
nn5 = knn2nb(knearneigh(ab, 8))
w = nb2listw(nn5, style="B")
joincount.test( as.factor(ab$Presence), w)
'../data/GroundTruthing/Iteration1Pts.shp'
st_read('../data/GroundTruthing/Iteration1Pts.shp')
iter1 <- st_read('../data/GroundTruthing/Iteration1Pts.shp')
View(iter1)
iter1gt <- st_read('../data/GroundTruthing/Iteration1Pts.shp')
library(sf)
library(tidyverse)
library(terra)
source('functions.R')
set.seed(23)
ground_truth <- read.csv('../data/GroundTruthing/Pts.csv') |>
mutate(
across(c('Dominant_Phen'), ~ na_if(., '')),
across(Presence_M:Presence_J, ~ replace_na(., 0)))
rand_pts_iter1 <- st_read('../data/GroundTruthPts/Iteration1-cp.shp', quiet = T) |>
select(UID) %>%
inner_join(., ground_truth, by = c('UID' = 'GlobalRandomID')) |>
mutate(Site = paste0('r-', UID)) |>
select(-Latitude, -Longitude, -UID)
ground_truth <- filter(ground_truth, is.na(GlobalRandomID)) # remove these random pts
revisits <- st_read('../data/GroundTruthPts/Revisits-cp.shp', quiet = T) |>
select(UID) |>
mutate(UID = str_replace(UID, 'P', 'p')) %>%
inner_join(., filter(ground_truth, str_detect(Site, 'p')), by = c('UID' = 'Site'))
ground_truth <- filter(ground_truth, str_detect(Site, 'p', negate= T)) |>
select(-GlobalRandomID) |>
st_as_sf(coords = c(x = 'Longitude', y = 'Latitude'), crs = 4269) |>
st_transform(st_crs(revisits))
revisits <- filter(revisits, !is.na(Latitude)) |>
st_drop_geometry() |>
st_as_sf(coords = c(x = 'Longitude', y = 'Latitude'), crs = 4269) |>
st_transform(st_crs(revisits)) %>%
bind_rows(., filter(revisits, is.na(Latitude))) |>
mutate(Site = UID) |>
select(-Latitude, -Longitude, -UID)
ground_truth <- bind_rows(ground_truth, rand_pts_iter1, revisits) |>
select(-GlobalRandomID) %>%
mutate(Presence = ifelse(Presence_M > 0 | Presence_J > 0, 1, 0), .after = Presence_J)
View(ground_truth)
library(sf)
library(tidyverse)
library(terra)
source('functions.R')
set.seed(23)
ground_truth <- read.csv('../data/GroundTruthing/Pts.csv') |>
mutate(
across(c('Dominant_Phen'), ~ na_if(., '')),
across(Presence_M:Presence_J, ~ replace_na(., 0)))
rand_pts_iter1 <- st_read('../data/GroundTruthPts/Iteration1-cp.shp', quiet = T) |>
select(UID) %>%
inner_join(., ground_truth, by = c('UID' = 'GlobalRandomID')) |>
mutate(Site = paste0('r-', UID)) |>
select(-Latitude, -Longitude, -UID)
ground_truth <- filter(ground_truth, is.na(GlobalRandomID)) # remove these random pts
revisits <- st_read('../data/GroundTruthPts/Revisits-cp.shp', quiet = T) |>
select(UID) |>
mutate(UID = str_replace(UID, 'P', 'p')) %>%
inner_join(., filter(ground_truth, str_detect(Site, 'p')), by = c('UID' = 'Site'))
ground_truth <- filter(ground_truth, str_detect(Site, 'p', negate= T)) |>
select(-GlobalRandomID) |>
st_as_sf(coords = c(x = 'Longitude', y = 'Latitude'), crs = 4269) |>
st_transform(st_crs(revisits))
revisits <- filter(revisits, !is.na(Latitude)) |>
st_drop_geometry() |>
st_as_sf(coords = c(x = 'Longitude', y = 'Latitude'), crs = 4269) |>
st_transform(st_crs(revisits)) %>%
bind_rows(., filter(revisits, is.na(Latitude))) |>
mutate(Site = UID) |>
select(-Latitude, -Longitude, -UID)
ground_truth <- bind_rows(ground_truth, rand_pts_iter1, revisits) |>
select(-GlobalRandomID) %>%
mutate(Presence = ifelse(Presence_M > 0 | Presence_J > 0, 1, 0), .after = Presence_J)
View(ground_truth)
st_write(ground_truth, '../data/GroundTruthing/QC.shp', append = F)
rm(rand_pts_iter1, revisits)
comp_abs <- read.csv('../data/GroundTruthing/ComputerAbs.csv') |>
mutate(Presence_M = 0, Presence_J = 0, Presence = 0) |>
st_as_sf(coords = c(x = 'Longitude', y = 'Latitude'), crs = 4326) |>
st_transform(st_crs(ground_truth))
View(comp_abs)
View(ground_truth)
comp_abs <- read.csv('../data/GroundTruthing/ComputerAbs.csv') |>
mutate(
Presence_M = 0, Presence_J = 0, Presence = 0 ) |>
st_as_sf(coords = c(x = 'Longitude', y = 'Latitude'), crs = 4326) |>
st_transform(st_crs(ground_truth))
ab <- bind_rows(ground_truth, comp_abs) |>
st_write('../data/GroundTruthing/Iteration1Pts.shp', append = F)
library(spdep)
nn5 = knn2nb(knearneigh(ab, 8))
w = nb2listw(nn5, style="B")
joincount.test( as.factor(ab$Presence), w)
occ_data <- bind_rows(
st_read('../data/collections/occurrences_coloradense/occurrences.shp', quiet = T) %>%
mutate(Occurrence = 1) %>%
st_transform(32613),
st_read('../data/spatial/processed/pseudo-absences/iteration1/absences.shp', quiet = T)
)
res <- c('3arc', '1arc', '1-3arc', '3m')
p2proc <- '../data/spatial/processed'
iter1gt <- st_read('../data/GroundTruthing/Iteration1Pts.shp')
View(iter1gt)
View(iter1gt)
View(occ_data)
plot(occ_data)
