mos[[2]],
wopt = c(names = 'Probability'),
filename = file.path(pout, paste0(resolution, '-Iteration', iteration, '-Pr.tif')))
unlink(file.path(pout, 'pr_tiles')) # remove the tiles we used for the probability surface.
} else { # in these cases, we only need to use a single tile for prediction, we can
# just use the existing virtual raster to do this.
terra::predict( # rasters, skip straight to modelling.
cores = 1, f = pr,
rast_dat, rf_model,
filename = file.path(pout, paste0(resolution, '-IterationCoarse', iteration, '.tif')),
wopt = c(names = 'predicted_suitability'),
overwrite = T)
writeRaster(
rast(file.path(pout, paste0(resolution, '-IterationCoarse', iteration, '.tif')))[[2]],
file.path(pout, paste0(resolution, '-Iteration', iteration, '-Pr.tif'))
)
file.remove(file.path(pout, paste0(resolution, '-IterationCoarse', iteration, '.tif')))
}
unlink(file.path(pout, 'pr_tiles'))
gc(verbose = FALSE)
###############      STANDARD ERROR PREDICTION        ########################
# the SE predictions are absurdly memory hungry, We will create 'tiles' to
# predict onto, and then combine them once the predictions are complete
if(se_prediction == TRUE){
if(resolution == '3arc'){ntile = 2} else # 4 tiles
if(resolution == '1arc'){ntile = 5} else # 25 tiles Needed # earlier iteration with 16 FAILED
if(resolution == '1-3arc'){ntile = 9} else # 81 tiles
if(resolution == '3m'){ntile = 13} # 169 tiles.
# if(exists())
dir.create( file.path(pout, 'tiles'), showWarnings = F)
dir.create( file.path(pout, 'se_tiles'), showWarnings = F)
template <- rast(nrows = ntile, ncols = ntile, extent = ext(rast_dat), crs = crs(rast_dat))
message('Making tiles for prediction of standard errors')
terra::makeTiles(rast_dat, template, filename = file.path(pout, 'tiles', "tile_.tif"))
tiles <- file.path(pout, 'tiles', list.files(file.path(pout, 'tiles')))
se <- function(...) predict(..., type = 'se', se.method = 'infjack',
predict.all = FALSE,
probability = TRUE, num.threads = cores)$se
# # predict the standard error onto the tiles.
# create and initialize progress bar
pb <- txtProgressBar(
min = 0,  max = length(tiles), style = 3, width = 50, char = "+")
for (i in seq_along(tiles)){
terra::predict(
rast(tiles[i]), rf_model, f = se,
filename = file.path(pout, 'se_tiles', paste0('SE', i, '.tif')),
overwrite = T, na.rm=TRUE)
setTxtProgressBar(pb, i)
}
close(pb)
mos <- terra::mosaic(sprc(
file.path(pout, 'se_tiles', list.files(file.path(pout, 'se_tiles')))
), fun = 'mean')
writeRaster(
mos[[2]],
wopt = c(names = 'standardError'),
filename = file.path(pout, paste0(resolution, '-Iteration', iteration, '-SE.tif')))
unlink(file.path(pout, 'tiles')); unlink(file.path(pout, 'se_tiles'))
gc(verbose = FALSE)
}
}
d <- modeller(x = occ_data, resolution = '3arc', iteration = 1)
rf_model <- ranger::ranger(
Occurrence ~ ., data = d, probability = T, keep.inbag = TRUE, importance = 'permutation')
View(rf_model)
rf_model[["variable.importance"]]
#' @param x input occurrence data
#' @param resolution list of paths to geodata at different resolutions.
#' @param iteration numeric, which iteration of modelling is being performed?
#' @param se_prediction boolean, whether to predict the SE surfaces or not, can add roughly
#' a week onto the prediction at 3m.
modeller <- function(x, resolution, iteration, se_prediction){
if(missing(se_prediction)){se_prediction <- FALSE}
rast_dat <- rastReader(paste0('dem_', resolution), p2proc)
df <- dplyr::bind_cols(
dplyr::select(x, Occurrence),
dplyr::select(terra::extract(rast_dat, x), -ID),
) |>
tidyr::drop_na() %>%
dplyr::mutate(
Occurrence = as.factor(Occurrence),
Pennock = as.factor(Pennock),
geomorphons = as.factor(geomorphons),
Longitude = unlist(purrr::map(.$geometry,1)),
Latitude  = unlist(purrr::map(.$geometry,2))) |>
sf::st_drop_geometry()
#######################         MODELLING           ##########################
# this is the fastest portion of this process. It will take at most a few minutes
# at any resolution, the goal of this paper wasn't really focused on comparing
# mutliple models of families nor messing with parameters, so we use Random Forest
# simply because they work very well with default settings, almost 'controlling'
# for stochasticity in this portion of the work.
# first we will perform boruta analysis, this will drop variables which have
# no relationship to the marks at the resolution under analysis.
# RandomForests do an excellent job of this - likely better than Boruta analysis...
# However what ends up happening is that many vars with very minor contributions to the
# model are kept. When it comes time to predict these models onto gridded surfaces
# these added terms (oftentimes requiring the re-reading of the rasters in a virtual context)
# make the prediction take AGES.
# We want to avoid everything taking ages.
cores <- parallel::detectCores()
BorutaRes <- Boruta::Boruta(Occurrence ~ ., data = df, num.threads = cores, doTrace = 0)
importance <- Boruta::attStats(BorutaRes)
rn <- rownames(importance[importance$decision %in% c('Confirmed'),])
important_vars <- Boruta::getSelectedAttributes(BorutaRes, withTentative = F)
df <- dplyr::select(df, dplyr::all_of(c('Occurrence', important_vars)))
rm(BorutaRes, importance, rn, important_vars)
# split the input data into both an explicit train and test data set.
TrainIndex <- caret::createDataPartition(
df$Occurrence, p = .8, list = FALSE, times = 1)
Train <- df[ TrainIndex,]; Test <- df[-TrainIndex,]
# perform the random forest modelling using default settings.
rf_model <- ranger::ranger(
Occurrence ~ ., data = Train, probability = T, keep.inbag = TRUE,
importance = 'permutation')
# save the model
saveRDS(rf_model,
file = paste0('../results/models/', resolution, '-Iteration', iteration, '.rds'))
# save the confusion matrix
predictions <- predict(rf_model, Test, type = 'se', se.method = 'infjack', probability=TRUE)
predictions$binary <- as.factor(if_else(predictions$predictions[,2] <= 0.49, 0, 1))
cmRestrat <- caret::confusionMatrix(predictions$binary, Test$Occurrence,
prevalence = 1, mode = 'everything')
saveRDS(cmRestrat,
file = paste0('../results/tables/', resolution, '-Iteration', iteration, '.rds'))
# we will also save the Pr-AUC as some folks find it a useful metric.
df <- data.frame(
truth = Test$Occurrence,
Class1 = predictions$predictions[,1]
)
yardstick::pr_auc(df, truth, Class1) |>
mutate(resolution = resolution, iteration = iteration) |>
write.csv(
paste0('../results/tables/', resolution, '-Iteration', iteration, '.csv'),
row.names = F)
# create these layers of coordinates for the models.
Longitude <- init(rast_dat, 'x') ; names(Longitude) <- 'Longitude'
Latitude <- init(rast_dat, 'y') ; names(Latitude) <- 'Latitude'
rast_dat <- c(rast_dat, Longitude, Latitude)
pout <- '../results/suitability_maps'
###################      PREDICT ONTO SURFACE        #########################
# this prediction is generally straightforward, it doesn't take an obscene
# amount of RAM and can happen relatively quickly, just overnight for the
# higher resolution scenarios.
if(!exists(file.path(pout, paste0(resolution, '-Iteration', iteration, '-Pr.tif')))){
pr <- function(...) predict(..., type = 'response', num.threads = 1)$predictions
if(resolution %in% c('3arc', '1arc', '1-3arc', '3m')){ntile = 1} else
if(resolution == '1m'){ntile = 3}
if(ntile > 1){
tile_path_4pr <- file.path(pout, paste0('tilesPR', '_', resolution))
if(exists(tile_path_4pr)){
message('Tiles already created for this resolution, skipping to prediction!\n')
} else {
dir.create(tile_path_4pr, showWarnings = F)
template <- rast(nrows = ntile, ncols = ntile, extent = ext(rast_dat), crs = crs(rast_dat))
message('Making tiles for prediction')
terra::makeTiles(rast_dat, template, filename = file.path(tile_path_4pr, "tile_.tif"))
}
tiles <- file.path(pout, 'tilesPR', list.files(file.path(pout, 'tilesPR')))
pr_tile_path <- file.path(pout, paste0('pr_tiles', '_', resolution, iteration))
dir.create(pr_tile_path, showWarnings = F)
message('Writing Predicted Probability to Raster using tiles - this while take some time')
pb <- txtProgressBar(
min = 0,  max = length(tiles), style = 3, width = 50, char = "+")
for (i in seq_along(tiles)){
terra::predict(
rast(tiles[i]), rf_model, f = pr,
filename = file.path(pr_tile_path, paste0(i, '.tif')),
overwrite = T, na.rm=TRUE)
setTxtProgressBar(pb, i)
}
close(pb)
mos <- terra::mosaic(sprc(
file.path(pr_tile_path, list.files(pr_tile_path))
), fun = 'mean')
writeRaster(
mos[[2]],
wopt = c(names = 'Probability'),
filename = file.path(pout, paste0(resolution, '-Iteration', iteration, '-Pr.tif')))
unlink(file.path(pout, 'pr_tiles')) # can remove the tiles we used for the probability surface.
} else { # in these cases, we only need to use a single tile for prediction, we can
# just use the existing virtual raster to do this.
message('Writing Predicted Probability to Raster')
terra::predict( # rasters, skip straight to modelling.
cores = 1, f = pr,
rast_dat, rf_model, cpkgs = "ranger",
filename = file.path(pout, paste0(resolution, '-IterationCoarse', iteration, '.tif')),
wopt = c(names = 'predicted_suitability'), na.rm=TRUE,
overwrite = T)
writeRaster( # we wrote a raster with both predicted class probabilities onto it.
# we don't want both, we are going to 'rewrite' the raster so only one class remains.
rast(file.path(pout, paste0(resolution, '-IterationCoarse', iteration, '.tif')))[[2]],
file.path(pout, paste0(resolution, '-Iteration', iteration, '-Pr.tif')),
overwrite = T
)
file.remove(file.path(pout, paste0(resolution, '-IterationCoarse', iteration, '.tif')))
}
unlink(file.path(pout, 'pr_tiles'))
}
gc(verbose = FALSE)
###############      STANDARD ERROR PREDICTION        ########################
# the SE predictions are absurdly memory hungry, We will create 'tiles' to
# predict onto, and then combine them once the predictions are complete
if(se_prediction == TRUE){
tile_path_4se <- file.path(pout, paste0(resolution, 'TilesSE'))
final_se_path <- file.path(pout, paste0(resolution, 'SETiles'))
if(resolution == '3arc'){ntile = 2} else # 4 tiles
if(resolution == '1arc'){ntile = 5} else # 25 tiles Needed # earlier iteration with 16 FAILED
if(resolution == '1-3arc'){ntile = 9} else # 81 tiles
if(resolution == '3m'){ntile = 13} # 169 tiles. # earlier iteration with 144 FAILED.
# don't create the tiles if they already exist.
if(exists(tile_path_4se)){
message('Tiles for SE exist at this resolution, skipping to predict.')} else {
message('Making tiles for prediction of standard errors')
dir.create(tile_path_4se, showWarnings = F)
dir.create(final_se_path, showWarnings = F)
template <- rast(nrows = ntile, ncols = ntile, extent = ext(rast_dat), crs = crs(rast_dat))
terra::makeTiles(rast_dat, template, filename = file.path(tile_path_4se, "tile_.tif"))
}
tiles <- file.path(tile_path_4se, list.files(tile_path_4se))
se <- function(...) predict(..., type = 'se', se.method = 'infjack',
predict.all = FALSE,
probability = TRUE, num.threads = cores)$se
# # predict the standard error onto the tiles.
# create and initialize progress bar
message('Predicting SE to tiles; this may take a really long time')
pb <- txtProgressBar(
min = 0,  max = length(tiles), style = 3, width = 50, char = "+")
for (i in seq_along(tiles)){
terra::predict(
rast(tiles[i]), rf_model, f = se,
filename = file.path(final_se_path, paste0('SE', i, '.tif')),
overwrite = T, na.rm=TRUE)
setTxtProgressBar(pb, i)
gc(verbose = FALSE)
}
close(pb)
mos <- terra::mosaic(sprc(
file.path(final_se_path, list.files(final_se_path))
), fun = 'mean')
writeRaster(
mos[[2]],
wopt = c(names = 'standardError'),
filename = file.path(pout, paste0(resolution, '-Iteration', iteration, '-SE.tif')),
overwrite = T)
gc(verbose = FALSE)
}
unlink(final_se_path)
}
library(sf)
library(tidyverse)
library(terra)
source('functions.R')
set.seed(23)
occ_data <- bind_rows(
st_read('../data/collections/occurrences_coloradense/occurrences.shp', quiet = T) %>%
mutate(Occurrence = 1) %>%
st_transform(32613),
st_read('../data/spatial/processed/pseudo-absences/iteration1/absences.shp', quiet = T)
)
res <- c('3arc', '1arc', '1-3arc', '3m')
p2proc <- '../data/spatial/processed'
modeller(x = occ_data, resolution = '1arc', iteration = 1, se_prediction = TRUE)
#' @param x input occurrence data
#' @param resolution list of paths to geodata at different resolutions.
#' @param iteration numeric, which iteration of modelling is being performed?
#' @param se_prediction boolean, whether to predict the SE surfaces or not, can add roughly
#' a week onto the prediction at 3m.
modeller <- function(x, resolution, iteration, se_prediction){
if(missing(se_prediction)){se_prediction <- FALSE}
rast_dat <- rastReader(paste0('dem_', resolution), p2proc)
df <- dplyr::bind_cols(
dplyr::select(x, Occurrence),
dplyr::select(terra::extract(rast_dat, x), -ID),
) |>
tidyr::drop_na() %>%
dplyr::mutate(
Occurrence = as.factor(Occurrence),
Pennock = as.factor(Pennock),
geomorphons = as.factor(geomorphons),
Longitude = unlist(purrr::map(.$geometry,1)),
Latitude  = unlist(purrr::map(.$geometry,2))) |>
sf::st_drop_geometry()
#######################         MODELLING           ##########################
# this is the fastest portion of this process. It will take at most a few minutes
# at any resolution, the goal of this paper wasn't really focused on comparing
# mutliple models of families nor messing with parameters, so we use Random Forest
# simply because they work very well with default settings, almost 'controlling'
# for stochasticity in this portion of the work.
# only rerun modelling if a saved .rds object doesn't exist.
if(file.exists(paste0('../results/models/', resolution, '-Iteration', iteration, '.rds'))){
rf_model <- readRDS(paste0('../results/models/', resolution, '-Iteration', iteration, '.rds'))
message('An exising model for this resolution and iteration already exists; reloading it now for projection')
} else {
# first we will perform boruta analysis, this will drop variables which have
# no relationship to the marks at the resolution under analysis.
# RandomForests do an excellent job of this - likely better than Boruta analysis...
# However what ends up happening is that many vars with very minor contributions to the
# model are kept. When it comes time to predict these models onto gridded surfaces
# these added terms (oftentimes requiring the re-reading of the rasters in a virtual context)
# make the prediction take AGES.
# We want to avoid everything taking ages.
cores <- parallel::detectCores()
BorutaRes <- Boruta::Boruta(Occurrence ~ ., data = df, num.threads = cores, doTrace = 0)
importance <- Boruta::attStats(BorutaRes)
rn <- rownames(importance[importance$decision %in% c('Confirmed'),])
important_vars <- Boruta::getSelectedAttributes(BorutaRes, withTentative = F)
df <- dplyr::select(df, dplyr::all_of(c('Occurrence', important_vars)))
rm(BorutaRes, importance, rn, important_vars)
# split the input data into both an explicit train and test data set.
TrainIndex <- caret::createDataPartition(
df$Occurrence, p = .8, list = FALSE, times = 1)
Train <- df[ TrainIndex,]; Test <- df[-TrainIndex,]
# perform the random forest modelling using default settings.
rf_model <- ranger::ranger(
Occurrence ~ ., data = Train, probability = T, keep.inbag = TRUE,
importance = 'permutation')
# save the model
saveRDS(rf_model,
file = paste0('../results/models/', resolution, '-Iteration', iteration, '.rds'))
# save the confusion matrix
predictions <- predict(rf_model, Test, type = 'se', se.method = 'infjack', probability=TRUE)
predictions$binary <- as.factor(if_else(predictions$predictions[,2] <= 0.49, 0, 1))
cmRestrat <- caret::confusionMatrix(predictions$binary, Test$Occurrence,
prevalence = 1, mode = 'everything')
saveRDS(cmRestrat,
file = paste0('../results/tables/', resolution, '-Iteration', iteration, '.rds'))
# we will also save the Pr-AUC as some folks find it a useful metric.
df_prauc <- data.frame(
truth = Test$Occurrence,
Class1 = predictions$predictions[,1]
)
yardstick::pr_auc(df_prauc, truth, Class1) |>
mutate(resolution = resolution, iteration = iteration) |>
write.csv(
paste0('../results/tables/', resolution, '-Iteration', iteration, '.csv'),
row.names = F)
# create these layers of coordinates for the models.
Longitude <- init(rast_dat, 'x') ; names(Longitude) <- 'Longitude'
Latitude <- init(rast_dat, 'y') ; names(Latitude) <- 'Latitude'
rast_dat <- c(rast_dat, Longitude, Latitude)
pout <- '../results/suitability_maps'
rm(df, df_prauc, TrainIndex, Train, Test, predictions, cmRestrat, Longitude, Latitude)
}
###################      PREDICT ONTO SURFACE        #########################
# this prediction is generally straightforward, it doesn't take an obscene
# amount of RAM and can happen relatively quickly, just overnight for the
# higher resolution scenarios.
pr <- function(...) predict(..., type = 'response', num.threads = 1)$predictions
if(resolution %in% c('3arc', '1arc', '1-3arc', '3m')){ntile = 1} else
if(resolution == '1m'){ntile = 3}
if(ntile > 1){
tile_path_4pr <- file.path(pout, paste0('tilesPR', '_', resolution))
if(file.exists(tile_path_4pr)){
message('Tiles already created for this resolution, skipping to prediction!\n')
} else {
dir.create(tile_path_4pr, showWarnings = F); message('Making tiles for prediction')
template <- rast(nrows = ntile, ncols = ntile, extent = ext(rast_dat), crs = crs(rast_dat))
terra::makeTiles(rast_dat, template, filename = file.path(tile_path_4pr, "tile_.tif"))
rm(template)
}
tiles <- file.path(pout, 'tilesPR', list.files(file.path(pout, 'tilesPR')))
pr_tile_path <- file.path(pout, paste0('pr_tiles', '_', resolution, iteration))
dir.create(pr_tile_path, showWarnings = F)
message('Writing Predicted Probability to Raster using tiles - this while take some time')
pb <- txtProgressBar(
min = 0,  max = length(tiles), style = 3, width = 50, char = "+")
for (i in seq_along(tiles)){
terra::predict(
rast(tiles[i]), rf_model, f = pr,
filename = file.path(pr_tile_path, paste0(i, '.tif')),
overwrite = T, na.rm=TRUE)
setTxtProgressBar(pb, i)
gc(verbose = FALSE)
}
close(pb)
mos <- terra::mosaic(sprc(
file.path(pr_tile_path, list.files(pr_tile_path))
), fun = 'mean')
writeRaster(
mos[[2]],
wopt = c(names = 'Probability'),
filename = file.path(pout, paste0(resolution, '-Iteration', iteration, '-Pr.tif')))
rm(mos)
unlink(file.path(pout, 'pr_tiles')) # can remove the tiles we used for the probability surface.
} else { # in these cases, we only need to use a single tile for prediction, we can
# just use the existing virtual raster to do this.
message('Writing Predicted Probability to Raster')
terra::predict( # rasters, skip straight to modelling.
cores = 1, f = pr,
rast_dat, rf_model, cpkgs = "ranger",
filename = file.path(pout, paste0(resolution, '-IterationCoarse', iteration, '.tif')),
wopt = c(names = 'predicted_suitability'), na.rm=TRUE,
overwrite = T)
writeRaster( # we wrote a raster with both predicted class probabilities onto it.
# we don't want both, we are going to 'rewrite' the raster so only one class remains.
rast(file.path(pout, paste0(resolution, '-IterationCoarse', iteration, '.tif')))[[2]],
file.path(pout, paste0(resolution, '-Iteration', iteration, '-Pr.tif')),
overwrite = T
)
file.remove(file.path(pout, paste0(resolution, '-IterationCoarse', iteration, '.tif')))
}
unlink(file.path(pout, 'pr_tiles'))
gc(verbose = FALSE)
###############      STANDARD ERROR PREDICTION        ########################
# the SE predictions are absurdly memory hungry, We will create 'tiles' to
# predict onto, and then combine them once the predictions are complete
if(se_prediction == TRUE){
tile_path_4se <- file.path(pout, paste0(resolution, 'TilesSE'))
final_se_path <- file.path(pout, paste0(resolution, 'SETiles'))
if(resolution == '3arc'){ntile = 2} else # 4 tiles
if(resolution == '1arc'){ntile = 6} else # 36 tiles Needed # earlier iteration with 16 FAILED # iter w/ 25 failed on tile 18...
if(resolution == '1-3arc'){ntile = 10} else # 100 tiles
if(resolution == '3m'){ntile = 13} # 169 tiles. # earlier iteration with 144 FAILED.
# don't create the tiles if they already exist.
if(exists(tile_path_4se)){
message('Tiles for SE exist at this resolution, skipping to predict.')} else {
message('Making tiles for prediction of standard errors')
dir.create(tile_path_4se, showWarnings = F)
dir.create(final_se_path, showWarnings = F)
template <- rast(nrows = ntile, ncols = ntile, extent = ext(rast_dat), crs = crs(rast_dat))
terra::makeTiles(rast_dat, template, filename = file.path(tile_path_4se, "tile_.tif"))
rm(template)
}
tiles <- file.path(tile_path_4se, list.files(tile_path_4se))
se <- function(...) predict(..., type = 'se', se.method = 'infjack',
predict.all = FALSE,
probability = TRUE, num.threads = cores)$se
# # predict the standard error onto the tiles.
# create and initialize progress bar
message('Predicting SE to tiles; this may take a really long time')
pb <- txtProgressBar(
min = 0,  max = length(tiles), style = 3, width = 50, char = "+")
for (i in seq_along(tiles[])){
terra::predict(
rast(tiles[i]), rf_model, f = se,
filename = file.path(final_se_path, paste0('SE', i, '.tif')),
overwrite = T, na.rm=TRUE)
setTxtProgressBar(pb, i)
gc(verbose = FALSE)
}
close(pb)
mos <- terra::mosaic(sprc(
file.path(final_se_path, list.files(final_se_path))
), fun = 'mean')
writeRaster(
mos[[2]],
wopt = c(names = 'standardError'),
filename = file.path(pout, paste0(resolution, '-Iteration', iteration, '-SE.tif')),
overwrite = T)
gc(verbose = FALSE)
}
unlink(final_se_path)
}
library(sf)
library(tidyverse)
library(terra)
source('functions.R')
set.seed(23)
occ_data <- bind_rows(
st_read('../data/collections/occurrences_coloradense/occurrences.shp', quiet = T) %>%
mutate(Occurrence = 1) %>%
st_transform(32613),
st_read('../data/spatial/processed/pseudo-absences/iteration1/absences.shp', quiet = T)
)
res <- c('3arc', '1arc', '1-3arc', '3m')
p2proc <- '../data/spatial/processed'
View(modeller)
modeller(x = occ_data, resolution = '1-3arc', iteration = 1, se_prediction = TRUE)
library(sf)
library(tidyverse)
library(terra)
source('functions.R')
set.seed(23)
occ_data <- bind_rows(
st_read('../data/collections/occurrences_coloradense/occurrences.shp', quiet = T) %>%
mutate(Occurrence = 1) %>%
st_transform(32613),
st_read('../data/spatial/processed/pseudo-absences/iteration1/absences.shp', quiet = T)
)
res <- c('3arc', '1arc', '1-3arc', '3m')
p2proc <- '../data/spatial/processed'
modeller(x = occ_data, resolution = '1-3arc', iteration = 1, se_prediction = TRUE)
modeller(x = occ_data, resolution = '1-3arc', iteration = 1, se_prediction = TRUE)
library(sf)
library(tidyverse)
library(terra)
source('functions.R')
set.seed(23)
occ_data <- bind_rows(
st_read('../data/collections/occurrences_coloradense/occurrences.shp', quiet = T) %>%
mutate(Occurrence = 1) %>%
st_transform(32613),
st_read('../data/spatial/processed/pseudo-absences/iteration1/absences.shp', quiet = T)
)
res <- c('3arc', '1arc', '1-3arc', '3m')
p2proc <- '../data/spatial/processed'
modeller(x = occ_data, resolution = '1-3arc', iteration = 1, se_prediction = TRUE)
library(tidyverse)
library(sf)
library(terra)
setwd('/media/steppe/hdd/EriogonumColoradenseTaxonomy/scripts')
# first we will create a domain for all analysis. The 'closest' this bounding box is to a known
# occurrence is 10 miles. The furthest distances vary.
domain <- sf::st_read('../data/collections/occurrences_coloradense/occurrences.shp', quiet = T) %>%
st_union() %>%
st_transform(32613) %>%
st_buffer(16093) %>%
st_transform(4326) %>%
vect()
ext(domain)
template <- rast(project(domain, 'EPSG:32613'), nrows = 5, ncols = 5)
