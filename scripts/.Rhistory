#'
#' @description This function helps subset the input data (x) to combinations of distOrders- where
#' points within x distance of the raster tile resolution are removed, and PAratios the ratio
#' of presence to absence points - which is used to control the excess of absence points.
#' @param x an sf/dataframe/tibble. All potential records which could be used for modelling
#' @param distOrder Numeric. The multiple of the resolution to remove near absences by. One of: 0, 1, 2, 4, 8 etc.
#' @param PAratio Numeric. The denominator of the ratio, Presence is always 1, so 1.5 would indicate
#' 100 presence records and 150 absence records.
#' @param resolution Numeric. The approximate resolution of the input data set, one of: 3, 10, 30, 90.
distOrder_PAratio_simulator <- function(x, distOrder, PAratio, resolution, ...){
#' Generate data sets for SD modelling at different configurations of distOrders and PAratios
#'
#' @description This function helps subset the input data (x) to combinations of distOrders- where
#' points within x distance of the raster tile resolution are removed, and PAratios the ratio
#' of presence to absence points - which is used to control the excess of absence points.
#' @param x an sf/dataframe/tibble. All potential records which could be used for modelling
#' @param distOrder Numeric. The multiple of the resolution to remove near absences by. One of: 0, 1, 2, 4, 8 etc.
#' @param PAratio Numeric. The denominator of the ratio, Presence is always 1, so 1.5 would indicate
#' 100 presence records and 150 absence records.
#' @param resolution Numeric. The approximate resolution of the input data set, one of: 3, 10, 30, 90.
distOrder_PAratio_simulator <- function(x, distOrder, PAratio, resolution, ...){
res_string <- switch(
as.character(resolution),
"3" = "3m",
"10" = "1-3arc",
"30" = "1arc",
"90" = "3arc",
stop("Input to `resolution` invalid. Need be one of: 3, 10, 30, 90")
)
# subset to absence points at distance intervals from presence points.
# This accomplishes the distOrder parameter.
abs <- x[x$Occurrence==0,]
prs <- x[x$Occurrence==1,]
abs <- abs[as.numeric(sf::st_distance(
abs,
prs[sf::st_nearest_feature(abs, prs),], by_element = TRUE
)) > (distOrder*resolution),]
# now recombine the data, we will sample down to get the PA ratio we need.
x <- dplyr::bind_rows(prs, abs)
# results indicate that 3:1 is pretty good, but very conservative in terms of suitable habitat
abs <- abs[sample(1:nrow(abs), size =  nrow(prs) * PAratio, replace = F),]
x <- dplyr::bind_rows(prs, abs)
modeller(x, PAratio = paste0("1:", PAratio),
resolution = res_string, distOrder = paste0('DO:', distOrder), ...)
}
table(m30$Occurrence)
View(m30)
library(tidyverse)
library(sf)
library(terra)
source('functions.R')
set.seed(27)
occ <-  st_read('../data/collections/occurrences_coloradense/occurrences.shp', quiet = T) %>%
mutate(
Longitude = unlist(map(.$geometry,1)),
Latitude = unlist(map(.$geometry,2)),
Species = 'Eriogonum coloradense'
) %>% # do this to explicitly drop repeat observations
distinct(Longitude, Latitude, .keep_all = T)
thinned <- spThin::thin(
loc.data = occ, lat.col = 'Latitude', long.col = 'Longitude', spec.col = 'Species',
thin.par = 0.09, reps = 100, write.files = FALSE, write.log.file = FALSE,
locs.thinned.list.return = TRUE)
thinned <- thinned[[which.max(unlist(lapply(thinned, nrow)))]] %>%
st_as_sf(coords = c(x = 'Longitude', y = 'Latitude'), crs = 4326)
occ <- occ[ lengths(st_intersects(occ, thinned)) > 0, ] %>%
dplyr::select(-Longitude, -Latitude) %>%
st_transform(32613)
rm(thinned)
p2proc <- '../data/spatial/processed'
arc3 <- rastReader('dem_3arc', p2proc)
# we want to be SURE that we are finding more populations, or segments of populations
# during this iteration of field sampling. Accordingly, we will want a model which
# is more conservative in predicting suitable habitat.
PA_possible <- sdm::background(arc3,
n = nrow(occ) + (nrow(occ)*0.9),
method = 'eDist', sp = occ) %>%
select(x, y) %>%
st_as_sf(coords = c(x = 'x', y = 'y'), crs = 32613) %>%
mutate(Occurrence = 0, ID = 1:nrow(.))
p2proc <- '../data/spatial/processed'
m30 <- sf::st_read("../data/Data4modelling/30m-presence-iter1.gpkg") %>%
rename(Occurrence = Presenc) |>
filter(Occurrence == 1)
arc1 <- rastReader('dem_1arc', p2proc)
# need to apply vifcor to get results, co-linear features will wreck the computations
v1 <- usdm::vifcor(arc1)
# need to apply vifcor to get results, co-linear features will wreck the computations
v1 <- usdm::vifcor(arc1)
arc1 <- usdm::exclude(arc1, v1)
PA_possible <- sdm::background(arc1,
n = nrow(m30)*3.5,# we want some extra's just in case to push this ratio up.
method = 'gDist', sp = vect(m30)) %>%
select(x, y) %>%
st_as_sf(coords = c(x = 'x', y = 'y'), crs = 32613) %>%
mutate(Occurrence = 0, ID = 1:nrow(.))
st_write(PA_possible, '../data/Data4modelling/iter1-pa.gpkg', append = FALSE)
ggplot() +
geom_sf(data= PA_possible) +
geom_sf(data = m30, color = 'red')
library(sf)
library(tidyverse)
library(terra)
library(caret)
source('functions.R')
set.seed(23)
p <- '../data/Data4modelling'
f <- file.path(p, list.files(p))
abs <- st_read('../data/Data4modelling/iter1-pa.gpkg')
m30 <- sf::st_read("../data/Data4modelling/90m-presence-iter1.gpkg") %>%
rename(Occurrence = Presenc) |>
sf::st_as_sf()
### we know that 1:1 absence to presence is far too low when including the 'local'
# absences.
m30 <- bind_rows(m30, abs)
m30 <- filter(m30, st_is(m30, "POINT")) |>
select(Occurrence)
distOrder_PAratio_simulator(
x = m30, distOrder = 2, PAratio = 2.6,
resolution = 90, iteration = 1, se_prediction = FALSE,
train_split = 0.9, p2proc = '../data/spatial/processed'
)
source('functions.R')
distOrder_PAratio_simulator(
x = m30, distOrder = 2, PAratio = 2.6,
resolution = 90, iteration = 1, se_prediction = FALSE,
train_split = 0.9, p2proc = '../data/spatial/processed'
)
#' Generate data sets for SD modelling at different configurations of distOrders and PAratios
#'
#' @description This function helps subset the input data (x) to combinations of distOrders- where
#' points within x distance of the raster tile resolution are removed, and PAratios the ratio
#' of presence to absence points - which is used to control the excess of absence points.
#' @param x an sf/dataframe/tibble. All potential records which could be used for modelling
#' @param distOrder Numeric. The multiple of the resolution to remove near absences by. One of: 0, 1, 2, 4, 8 etc.
#' @param PAratio Numeric. The denominator of the ratio, Presence is always 1, so 1.5 would indicate
#' 100 presence records and 150 absence records.
#' @param resolution Numeric. The approximate resolution of the input data set, one of: 3, 10, 30, 90.
distOrder_PAratio_simulator <- function(x, distOrder, PAratio, resolution, ...){
res_string <- switch(
as.character(resolution),
"3" = "3m",
"10" = "1-3arc",
"30" = "1arc",
"90" = "3arc",
stop("Input to `resolution` invalid. Need be one of: 3, 10, 30, 90")
)
# subset to absence points at distance intervals from presence points.
# This accomplishes the distOrder parameter.
abs <- x[x$Occurrence==0,]
prs <- x[x$Occurrence==1,]
abs <- abs[as.numeric(sf::st_distance(
abs,
prs[sf::st_nearest_feature(abs, prs),], by_element = TRUE
)) > (distOrder*resolution),]
# now recombine the data, we will sample down to get the PA ratio we need.
x <- dplyr::bind_rows(prs, abs)
# results indicate that 3:1 is pretty good, but very conservative in terms of suitable habitat
abs <- abs[sample(1:nrow(abs), size =  nrow(prs) * PAratio, replace = F),]
x <- dplyr::bind_rows(prs, abs)
modeller(x, PAratio = paste0("1:", PAratio),
resolution = res_string, distOrder = paste0('DO:', distOrder), ...)
}
distOrder_PAratio_simulator(
x = m30, distOrder = 2, PAratio = 2.6,
resolution = 90, iteration = 1, se_prediction = FALSE,
train_split = 0.9, p2proc = '../data/spatial/processed'
)
distOrder_PAratio_simulator(
x = m30, distOrder = 2, PAratio = 3.0,
resolution = 90, iteration = 1, se_prediction = FALSE,
train_split = 0.9, p2proc = '../data/spatial/processed'
)
distOrder_PAratio_simulator(
x = m30, distOrder = 2, PAratio = 3.4,
resolution = 90, iteration = 1, se_prediction = FALSE,
train_split = 0.9, p2proc = '../data/spatial/processed'
)
abs <- st_read('../data/Data4modelling/iter1-pa.gpkg')
m30 <- sf::st_read("../data/Data4modelling/90m-presence-iter1.gpkg") %>%
rename(Occurrence = Presenc) |>
sf::st_as_sf()
### we know that 1:1 absence to presence is far too low when including the 'local'
# absences.
m30 <- bind_rows(m30, abs)
m30 <- filter(m30, st_is(m30, "POINT")) |>
select(Occurrence)
distOrder_PAratio_simulator(
x = m30, distOrder = 1, PAratio = 2.7,
resolution = 90, iteration = 1, se_prediction = FALSE,
train_split = 0.9, p2proc = '../data/spatial/processed'
)
distOrder_PAratio_simulator(
x = m30, distOrder = 1, PAratio = 3,
resolution = 90, iteration = 1, se_prediction = FALSE,
train_split = 0.9, p2proc = '../data/spatial/processed'
)
abs <- st_read('../data/Data4modelling/iter1-pa.gpkg')
m30 <- sf::st_read("../data/Data4modelling/30m-presence-iter1.gpkg") %>%
rename(Occurrence = Presenc) |>
sf::st_as_sf()
### we know that 1:1 absence to presence is far too low when including the 'local'
# absences.
m30 <- bind_rows(m30, abs)
m30 <- filter(m30, st_is(m30, "POINT")) |>
select(Occurrence)
distOrder_PAratio_simulator(
x = m30, distOrder = 0, PAratio = 2.7,
resolution = 30, iteration = 1, se_prediction = FALSE,
train_split = 0.9, p2proc = '../data/spatial/processed'
)
distOrder_PAratio_simulator(
x = m30, distOrder = 0, PAratio = 3.0,
resolution = 30, iteration = 1, se_prediction = FALSE,
train_split = 0.9, p2proc = '../data/spatial/processed'
)
distOrder_PAratio_simulator(
x = m30, distOrder = 2, PAratio = 2.7,
resolution = 30, iteration = 1, se_prediction = FALSE,
train_split = 0.9, p2proc = '../data/spatial/processed'
)
distOrder_PAratio_simulator(
x = m30, distOrder = 2, PAratio = 3.0,
resolution = 30, iteration = 1, se_prediction = FALSE,
train_split = 0.9, p2proc = '../data/spatial/processed'
)
library(sf)
library(tidyverse)
library(terra)
library(caret)
source('functions.R')
set.seed(23)
p <- '../data/Data4modelling'
f <- file.path(p, list.files(p))
abs <- st_read('../data/Data4modelling/iter1-pa.gpkg')
m30 <- sf::st_read("../data/Data4modelling/30m-presence-iter1.gpkg") %>%
rename(Occurrence = Presenc) |>
sf::st_as_sf()
### we know that 1:1 absence to presence is far too low when including the 'local'
# absences.
m30 <- bind_rows(m30, abs)
m30 <- filter(m30, st_is(m30, "POINT")) |>
select(Occurrence)
```{r}
rast_dat <- rastReader(paste0('dem_', resolution), p2proc)
cores <- parallel::detectCores()
resolution = 30, iteration = 1, se_prediction = FALSE,
rast_dat <- rastReader(paste0('dem_', resolution), p2proc)
resolution = 30, iteration = 1, se_prediction = FALSE,
resolution = 30
train_split = 0.9; p2proc = '../data/spatial/processed'
rast_dat <- rastReader(paste0('dem_', resolution), p2proc)
paste0('dem_', resolution)
paste0('dem_', resolution), p2proc
paste0('dem_', resolution)
rast_dat <- rastReader(paste0('dem_', resolution), p2proc)
file.path(p2proc, paste0( 'dem_', resolution))
rast_dat <- rastReader(file.path(p2proc, paste0( 'dem_', resolution)))
train_split = 0.9; p2proc = '../data/spatial/processed'
rast_dat <- rastReader(file.path(p2proc, paste0( 'dem_', resolution)))
p2proc = '../data/spatial/processed'
file.path(p2proc, paste0( 'dem_', resolution))
rast_dat <- rastReader(file.path(p2proc, paste0( 'dem_', resolution)))
rastReader(paste0('dem_', resolution), p2proc)
resolution = 30
resolution = "1arc"
rastReader(paste0('dem_', resolution), p2proc)
r <- rastReader(paste0('dem_', resolution), p2proc)
abs <- st_read('../data/Data4modelling/30m-count-iter1.gpkg')
ct <- st_read('../data/Data4modelling/30m-count-iter1.gpkg')
ct <- st_read('../data/Data4modelling/30m-count-iter1.gpkg')
resolution = "1arc"
train_split = 0.9; p2proc = '../data/spatial/processed'
View(ct)
resolution = "1arc"
train_split = 0.8; p2proc = '../data/spatial/processed'
View(ct)
r <- rastReader(paste0('dem_', resolution), p2proc)
source('functions.R')
r <- rastReader(paste0('dem_', resolution), p2proc)
cores <- parallel::detectCores()
View(ct)
ct <- st_read('../data/Data4modelling/30m-count-iter1.gpkg') |>
select(Prsnc_M)
resolution = "1arc"
train_split = 0.8; p2proc = '../data/spatial/processed'
r <- rastReader(paste0('dem_', resolution), p2proc)
df <- dplyr::bind_cols(
ct,
dplyr::select(terra::extract(rast_dat, ct), -ID),
) |>
tidyr::drop_na() %>%
dplyr::mutate(
Occurrence = as.factor(Occurrence)) |>#,
#     Pennock = as.factor(Pennock),
#    geomorphons = as.factor(geomorphons)) |>
sf::st_drop_geometry()
df <- dplyr::bind_cols(
ct,
dplyr::select(terra::extract(rast_dat, ct), -ID),
) #|>
rast_dat <- rastReader(paste0('dem_', resolution), p2proc)
cores <- parallel::detectCores()
df <- dplyr::bind_cols(
ct,
dplyr::select(terra::extract(rast_dat, ct), -ID),
) #|>
View(df)
df <- dplyr::bind_cols(
ct,
dplyr::select(terra::extract(rast_dat, ct), -ID),
) |>
tidyr::drop_na() %>%
sf::st_drop_geometry()
df <- dplyr::bind_cols(
ct,
dplyr::select(terra::extract(rast_dat, ct), -ID),
) |>
tidyr::drop_na()
saveRDS(df, '../data/test_ct_data.Rds')
test_ct_data <- readRDS("/media/steppe/hdd/EriogonumColoradenseTaxonomy/data/test_ct_data.Rds")
View(test_ct_data)
ct <- st_read('../data/Data4modelling/30m-count-iter1.gpkg') |>
select(Prsnc_M)
library(sf)
library(tidyverse)
library(terra)
library(caret)
source('functions.R')
set.seed(23)
library(xgboost)
r <- terra::rast('../results/suitability_maps/1arc-Iteration1-PA1_2.7DO_2-Pr.tif')
names(r) <- 'Pr.SuitHab'
r <- terra::rast('../results/suitability_maps/1arc-Iteration1-PA1_2.7DO_2-Pr.tif')
r <- terra::rast('../results/suitability_maps/1arc-Iteration1-PA1_2.7DO_2-Pr.tif')
getwd()
r <- terra::rast('../results/suitability_maps/1arc-Iteration1-PA1:2.7DO:2-Pr.tif')
names(r) <- 'Pr.SuitHab'
df <- readRDS('../data/test_ct_data.Rds')
df <- df |>
sf::st_drop_geometry() |>
bind_cols(
Pr.SuitHab = terra::extract(r, df)$Pr.SuitHab
)
df
plot(df$Longitude, df$Latitude)
plot(df$Latitude, df$Longitude)
df <- filter(Latitude > 42800000)
df <- filter(df, Latitude > 42800000)
df <- readRDS('../data/test_ct_data.Rds')
df <- df |>
sf::st_drop_geometry() |>
bind_cols(
Pr.SuitHab = terra::extract(r, df)$Pr.SuitHab
)
df <- filter(df, Latitude > 4280000)
plot(df$Latitude, df$Longitude)
# let's try and bring count back to it's 3x3m quadrat size, I think too big
# of numbers throws xgboost off.
df <- mutate(df, Prsnc_M = Prsnc_M / 30)
data_split <- df |>
rsample::initial_split(strata = Prsnc_M, prop = 4/5)
train <- rsample::training(data_split)
test  <- rsample::testing(data_split)
indices_knndm <- CAST::knndm(
sf::st_as_sf(train, coords = c('Longitude', 'Latitude'), crs = 4326),
r,
space = 'feature',
k=10)
indices_knndm <- CAST::knndm(
sf::st_as_sf(train, coords = c('Longitude', 'Latitude'), crs = 4326),
r,
space = 'geographic',
k=10)
indices_knndm <- CAST::knndm(
sf::st_as_sf(train, coords = c('Longitude', 'Latitude'), crs = 4326),
r,
k=10)
xgb_reg_model <- parsnip::boost_tree(
mode = 'regression',
trees = tune(),
tree_depth = tune(),
min_n = tune(),
loss_reduction = tune(),
learn_rate = tune(),
stop_iter = tune()
) |>
parsnip::set_engine("xgboost", objective = "count:poisson")
doParallel::registerDoParallel()
model_params <- xgb_reg_model |>
finetune::tune_sim_anneal(rec, # about 10-15 minutes to run
# honestly rarely beat the initial starts.
# even when greatly increasing the iterations.
resamples = indices_knndm, iter = 15, initial = parallel::detectCores()
)
rec <- recipes::recipe(Prsnc_M ~ ., data = train)
model_params <- xgb_reg_model |>
finetune::tune_sim_anneal(rec, # about 10-15 minutes to run
# honestly rarely beat the initial starts.
# even when greatly increasing the iterations.
resamples = indices_knndm, iter = 15, initial = parallel::detectCores()
)
rec <- recipes::recipe(Prsnc_M ~ ., data = train)
rs <- rsample::bootstraps(train, times = 15)
xgb_reg_model <- parsnip::boost_tree(
mode = 'regression',
trees = tune(),
tree_depth = tune(),
min_n = tune(),
loss_reduction = tune(),
learn_rate = tune(),
stop_iter = tune()
) |>
parsnip::set_engine("xgboost", objective = "count:poisson")
doParallel::registerDoParallel()
model_params <- xgb_reg_model |>
finetune::tune_sim_anneal(rec, # about 10-15 minutes to run
# honestly rarely beat the initial starts.
# even when greatly increasing the iterations.
resamples = indices_knndm, iter = 15, initial = parallel::detectCores()
)
model_params <- xgb_reg_model |>
finetune::tune_sim_anneal(rec, # about 10-15 minutes to run
# honestly rarely beat the initial starts.
# even when greatly increasing the iterations.
resamples = rs, iter = 15, initial = parallel::detectCores()
)
best_param <- tune::select_best(model_params, metric = "rmse")
xgb_reg_model <- xgb_reg_model |>
tune::finalize_model(best_param)
xgb_fit <- xgb_reg_model %>%
fit(Prsnc_M ~ ., data = train)
xgb_fit <- xgb_reg_model %>%
fit(Prsnc_M ~ ., data = train)
wflow <- workflows::workflow() %>%
workflows::add_model(xgb_reg_model) %>%
workflows::add_recipe(rec)
wflow <- workflows::workflow() %>%
workflows::add_model(xgb_reg_model) %>%
workflows::add_recipe(rec)
test_pred <- data.frame(
'Observed' = test$Prsnc_M,
'Predicted' = stats::predict(xgb_fit, new_data = test)
)
par(pty="s")
plot(test_pred$Observed, test_pred$.pred)
vip::vip(xgb_fit, num_features = 20)
par(pty="s")
plot(test_pred$Observed, test_pred$.pred)
plot(test_pred$Observed, test_pred$.pred, col = rgb(test$Pr.SuitHab, max=255))
cr <- colorRamp(c("green", "black"))
par(pty="s")
plot(test_pred$Observed, test_pred$.pred, col = rgb(test$Pr.SuitHab, max=255))
plot(test_pred$Observed, test_pred$.pred, col = rgb(test$Pr.SuitHab, test$Pr.SuitHab, max=255))
plot(test_pred$Observed, test_pred$.pred, col = rgb(test$Pr.SuitHab/ test$Pr.SuitHab, max=255))
cr <- colorRamp(c("green", "black"))
par(pty="s")
plot(test_pred$Observed, test_pred$.pred, col = rgb(test$Pr.SuitHab/ test$Pr.SuitHab, max=255))
plot(test_pred$Observed, test_pred$.pred)
ggplot(data = test_pred) +
geom_point(aes(x = Observed, y = .pred))
test_pred <- data.frame(
'Observed' = test$Prsnc_M,
'Predicted' = stats::predict(xgb_fit, new_data = test),
'Pr.suit' = test$Pr.SuitHab
)
ggplot(data = test_pred) +
geom_point(aes(x = Observed, y = .pred, fill = Pr.suit))
ggplot(data = test_pred) +
geom_point(aes(x = Observed, y = .pred, color = Pr.suit))
library(xgboost)
getwd()
r <- terra::rast('../results/suitability_maps/1arc-Iteration1-PA1:2.7DO:2-Pr.tif')
names(r) <- 'Pr.SuitHab'
df <- readRDS('../data/test_ct_data.Rds')
df <- df |>
sf::st_drop_geometry() |>
bind_cols(
Pr.SuitHab = terra::extract(r, df)$Pr.SuitHab
)
df <- filter(df, Latitude > 4280000)
# let's try and bring count back to it's 3x3m quadrat size, I think too big
# of numbers throws xgboost off.
df <- mutate(df, Prsnc_M = Prsnc_M / 30)
df <- filter(df, Prsnc_M > 0 | Pr.SuitHab > 0.45)
data_split <- df |>
rsample::initial_split(strata = Prsnc_M, prop = 4/5)
train <- rsample::training(data_split)
test  <- rsample::testing(data_split)
rec <- recipes::recipe(Prsnc_M ~ ., data = train)
indices_knndm <- CAST::knndm(
sf::st_as_sf(train, coords = c('Longitude', 'Latitude'), crs = 4326),
r,
k=10)
rs <- rsample::bootstraps(train, times = 15)
xgb_reg_model <- parsnip::boost_tree(
mode = 'regression',
trees = tune(),
tree_depth = tune(),
min_n = tune(),
loss_reduction = tune(),
learn_rate = tune(),
stop_iter = tune()
) |>
parsnip::set_engine("xgboost", objective = "count:poisson")
doParallel::registerDoParallel()
model_params <- xgb_reg_model |>
finetune::tune_sim_anneal(rec, # about 10-15 minutes to run
# honestly rarely beat the initial starts.
# even when greatly increasing the iterations.
resamples = rs, iter = 15, initial = parallel::detectCores()
)
