Infrarank = POW_Infrarank,
Infraspecies = POW_Infraspecies,
Infraspecific_authority = POW_Infra_authority,
Name_authority = POW_Name_authority,
Binomial_authority = POW_Binom_authority,
Genus = POW_Genus,
Epithet = POW_Epithet,
Slope = slope,
Aspect = aspect
)
data1 <- bind_rows(skipped, d_sub) |>
# d_sub |>
#filter(Primary_Collector != 'Rosalind Rowe') |>
arrange(Primary_Collector, as.numeric(Collection_number))
rm(d_sub, skipped, skips)
# first ensure the columns are in the same order as google sheets
processed_cols <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed - Examples') %>%
colnames()
# first ensure the columns are in the same order as google sheets
processed_cols <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed - Examples') %>%
colnames()
df <- data1 %>%
sf::st_drop_geometry() %>%
relocate(any_of(processed_cols)) %>%
arrange(Primary_Collector, Collection_number)
df |>
filter(Primary_Collector %in%
c('Reed Clark Benkendorf', 'Phoebe Smurthwaite', 'Kristen Countryman',
'Carrie Jan Finkelstein', 'Katie Peel', 'Liz Enoch', 'Rebecca Ubalde')) |>
write_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed COPL - 2024')
processed <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed COPL - 2024') %>%
mutate(UNIQUEID = paste0(Primary_Collector, Collection_number),
Coordinate_Uncertainty = '+/- 5m') %>%
# select(-Directions_BL) %>%
data.frame()
processed <- data.frame( apply(processed, 2, as.character) )
processed <- mutate(processed, Collection_number = as.numeric(Collection_number))
proc_split <- split(processed, processed$Primary_Collector)
fnames <- paste0('../results/collections-', gsub(' ', '_', names(proc_split)), '.csv')
for(i in 1:length(proc_split)) {
write.csv(proc_split[[i]], fnames[i], row.names = F)
}
dir.create('../HerbariumLabels/raw/Katie-raw')
p <- '/media/steppe/hdd/2024SOS_HerbariumSpecimens/HerbariumLabels/raw/Katie-raw'
purrr::walk(
.x = proc_split[['Katie Peel']]$Collection_number,
~ rmarkdown::render(
input = 'skeleton-Katie.Rmd',
output_file = file.path(p, glue::glue("{.x}.pdf")),
params = list(Collection_number = {.x})
)
)
# devtools::install_github('sagesteppe/BarnebyLives', force = TRUE)
library(tidyverse)
library(BarnebyLives)
library(googlesheets4)
library(textclean)
cjf <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed COPL - 2024') |>
filter(Primary_Collector == 'Katie Peel')
kp <- format_database_import(kp, 'Symbiota') |>
mutate(across(everything(), ~ as.character(.))) |>
mutate(across(everything(), ~ replace_na(., '')))
kp <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed COPL - 2024') |>
filter(Primary_Collector == 'Katie Peel')
kp <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed COPL - 2024') |>
filter(Primary_Collector == 'Katie Peel')
kp <- format_database_import(kp, 'Symbiota') |>
mutate(across(everything(), ~ as.character(.))) |>
mutate(across(everything(), ~ replace_na(., '')))
write.csv(kp, '../results/KatiePeel_SOS2024_Symbiota.csv', row.names = F)
pm <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed COPL - 2024') |>
filter(Primary_Collector == 'Phoebe Smurthwaite')
pm <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed COPL - 2024') |>
filter(Primary_Collector == 'Phoebe Smurthwaite')
pm <- format_database_import(pm, 'Symbiota') |>
mutate(across(everything(), ~ as.character(.))) |>
mutate(across(everything(), ~ replace_na(., '')))
write.csv(pm, '../results/PhoebeSmurthwaite_SOS2024_Symbiota.csv', row.names = F)
load("/media/steppe/hdd/BarnebyLives/data/herbaria_info.rda")
View(herbaria_info)
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(dpi = 300)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
write.csv(herbarium, 'HerbariumContacts.csv')
herbarium <- herbaria_info |>
dplyr::filter(Abbreviation == herbarium_code)
write.csv(herbarium, 'HerbariumContacts.csv')
herbarium <- herbaria_info |>
dplyr::filter(Abbreviation == herbarium_code)
library(BarnebyLives)
herbarium <- herbaria_info |>
dplyr::filter(Abbreviation == herbarium_code)
herbarium <- herbaria_info #|>
dplyr::filter(Abbreviation == herbarium_code)
write.csv(herbarium, 'HerbariumContacts.csv')
install.packages('CDSE')
View(processed)
library(CDSE)
dsn <- system.file("extdata", "centralpark.geojson", package = "CDSE")
aoi <- sf::read_sf(dsn, as_tibble = FALSE)
script_file <- system.file("scripts", "NDVI_uint8.js", package = "CDSE")
day <- "2023-07-11"
ras <- GetImage(aoi = aoi, time_range = day, script = script_file,
collection = "sentinel-2-l2a",format = "image/tiff",
mosaicking_order = "leastCC", resolution = 10, client = OAuthClient)
OAuthClient
library(CDSE)
Sys.getenv()
Sys.getenv()
Sys.getenv("CopernicusOAuthID")
OAuthClient <- GetOAuthClient(
id = Sys.getenv("CopernicusOAuthID"),
secret = Sys.getenv("CopernicusOAuthSecret")
)
library(CDSE)
OAuthClient <- GetOAuthClient(
id = Sys.getenv("CopernicusOAuthID"),
secret = Sys.getenv("CopernicusOAuthSecret")
)
dsn <- system.file("extdata", "centralpark.geojson", package = "CDSE")
aoi <- sf::read_sf(dsn, as_tibble = FALSE)
script_file <- system.file("scripts", "NDVI_uint8.js", package = "CDSE")
day <- "2023-07-11"
ras <- GetImage(aoi = aoi, time_range = day, script = script_file,
collection = "sentinel-2-l2a",format = "image/tiff",
mosaicking_order = "leastCC", resolution = 10, client = OAuthClient)
plot(ras)
library(terra)
plot(ras)
ras
script_file
script_file <- system.file("scripts", "RawBands.js", package = "CDSE")
day <- "2023-07-11"
ras <- GetImage(aoi = aoi, time_range = day, script = script_file,
collection = "sentinel-2-l2a", format = "image/tiff",
mosaicking_order = "leastCC", resolution = 10, client = OAuthClient)
plot(ras)
ras
GetCollections()
library(CDSE)
GetCollections()
as.Date('2015-04-01')
as.Date('2024-10-01')
library(tidyverse)
library(sf)
library(terra)
setwd('/media/steppe/hdd/EriogonumColoradenseTaxonomy/scripts')
# first we will create a domain for all analysis. The 'closest' this bounding box is to a known
# occurrence is 10 miles. The furthest distances vary.
domain <- sf::st_read('../data/collections/occurrences_coloradense/occurrences.shp', quiet = T) %>%
st_union() %>%
st_transform(32613) %>%
st_buffer(16093) %>%
st_transform(4326) %>%
vect()
ext(domain)
template <- rast(project(domain, 'EPSG:32613'), nrows = 5, ncols = 5)
View(template)
catalog_results <- SearchCatalog(
aoi = template,
from = as.Date('2015-04-01'), to = as.Date('2024-10-01'),
collection = "sentinel-2-l2a",
client = OAuthClient
)
library(CDSE)
library(terra)
st_bbox(template)
st_as_sfc(st_bbox(template))
aoi <- st_as_sfc(st_bbox(template))
catalog_results <- SearchCatalog(
aoi = aoi,
from = as.Date('2015-04-01'), to = as.Date('2024-10-01'),
collection = "sentinel-2-l2a",
client = OAuthClient
)
OAuthClient <- GetOAuthClient(
id = Sys.getenv("CopernicusOAuthID"),
secret = Sys.getenv("CopernicusOAuthSecret")
)
catalog_results <- SearchCatalog(
aoi = aoi,
from = as.Date('2015-04-01'), to = as.Date('2024-10-01'),
collection = "sentinel-2-l2a",
client = OAuthClient
)
View(catalog_results)
catalog_results <- SearchCatalog(
aoi = aoi,
from = as.Date('2016-04-01'), to = as.Date('2024-10-01'), # first relevant flights are in 2016
collection = "sentinel-2-l2a",
client = OAuthClient
)
View(catalog_results)
catalog_results <- SearchCatalog(
aoi = aoi,
from = as.Date('2017-04-01'), to = as.Date('2024-10-01'),
# first relevant flights are in 2017, a was flying in 2016, but we'll just skip that year to make writing methods easier
collection = "sentinel-2-l2a",
client = OAuthClient
)
catalog_results |>
mutate(Month = str_extract(acquisitionDate, '-[0-9]{2}-'))
mutate(Month = str_remove( str_extract(acquisitionDate, '-[0-9]{2}-'), '-')
catalog_results |>
catalog_results |>
mutate(Month = str_remove( str_extract(acquisitionDate, '-[0-9]{2}-'), '-'))
catalog_results |>
mutate(Month = str_remove_all( str_extract(acquisitionDate, '-[0-9]{2}-'), '-'))
catalog_results |>
mutate(Month = as.numeric(str_remove_all( str_extract(acquisitionDate, '-[0-9]{2}-'), '-')))
catalog_results |>
mutate(Month = as.numeric(str_remove_all( str_extract(acquisitionDate, '-[0-9]{2}-'), '-'))) |>
filter(Month >= 4, Month <= 9)
cr <- catalog_results |>
mutate(Month = as.numeric(str_remove_all( str_extract(acquisitionDate, '-[0-9]{2}-'), '-'))) |>
filter(Month >= 4, Month <= 9)
View(cr)
cr <- catalog_results |>
mutate(Month = as.numeric(str_remove_all( str_extract(acquisitionDate, '-[0-9]{2}-'), '-'))) |>
filter(Month >= 5, Month <= 8)
View(cr)
cr <- catalog_results |>
mutate(Month = as.numeric(str_remove_all( str_extract(acquisitionDate, '-[0-9]{2}-'), '-'))) |>
filter(Month >= 5, Month <= 8) |> # we want to detect late laying snow packs
group_by(acquisitionDate) |> # only bother with tiles which have good coverage on that day! No need for random tiles.
mutate(n = n())
View(cr)
cr <- catalog_results |>
mutate(Month = as.numeric(str_remove_all( str_extract(acquisitionDate, '-[0-9]{2}-'), '-'))) |>
filter(Month >= 5, Month <= 8) |> # we want to detect late laying snow packs
group_by(acquisitionDate) |> # only bother with tiles which have good coverage on that day! No need for random tiles.
mutate(n = n()) |>
filter(n > 4)
View(cr)
cr <- catalog_results |>
mutate(Month = as.numeric(str_remove_all( str_extract(acquisitionDate, '-[0-9]{2}-'), '-'))) |>
filter(Month >= 5, Month <= 7) |> # we want to detect late laying snow packs
group_by(acquisitionDate) |> # only bother with tiles which have good coverage on that day! No need for random tiles.
mutate(n = n()) |>
filter(n > 4)
View(cr)
cr <- catalog_results |>
mutate(Month = as.numeric(str_remove_all( str_extract(acquisitionDate, '-[0-9]{2}-'), '-'))) |>
filter(Month >= 5, Month <= 7) |> # we want to detect late laying snow packs
group_by(acquisitionDate) |> # only bother with tiles which have good coverage on that day! No need for random tiles.
mutate(
n = n(),
totalArea = sum(areaCoverage)) |>
filter(n > 4)
cr <- catalog_results |>
mutate(Month = as.numeric(str_remove_all( str_extract(acquisitionDate, '-[0-9]{2}-'), '-'))) |>
filter(Month >= 5, Month <= 7) |> # we want to detect late laying snow packs
group_by(acquisitionDate) |> # only bother with tiles which have good coverage on that day! No need for random tiles.
mutate(
totalArea = sum(areaCoverage),
n = n()) |>
filter(n > 4)
cr <- catalog_results |>
mutate(Month = as.numeric(str_remove_all( str_extract(acquisitionDate, '-[0-9]{2}-'), '-'))) |>
filter(Month >= 5, Month <= 7) |> # we want to detect late laying snow packs
group_by(acquisitionDate) |> # only bother with tiles which have good coverage on that day! No need for random tiles.
mutate(
totalArea = sum(areaCoverage),
n = n()) |>
filter(n > 4 & totalArea >= 100)
View(cr)
View(cr)
View(cr)
ggplot() +
geom_col(data = cr, aes(x = acquisitionDate))
ggplot() +
geom_col(data = cr, aes(x = acquisitionDate))
ggplot() +
geom_col(data = cr, aes(x = acquisitionDate))
head(cr)
ggplot() +
geom_col(data = cr, aes(x = acquisitionDate))
ggplot() +
geom_col(data = cr, aes(x = acquisitionDate, y = n))
cr <- catalog_results |>
mutate(Month = as.numeric(str_remove_all( str_extract(acquisitionDate, '-[0-9]{2}-'), '-'))) |>
filter(Month >= 5, Month <= 7) |> # we want to detect late laying snow packs
group_by(acquisitionDate) |> # only bother with tiles which have good coverage on that day! No need for random tiles.
mutate(
totalArea = sum(areaCoverage),
n = n()) |>
filter(n > 4 & totalArea >= 100) |>
mutate(
year = str_extract(acquisitionDate, '[0-9]{4}'),
)
View(cr)
ggplot() +
geom_col(data = cr, aes(x = acquisitionDate, y = n)) +
facet_wrap(~year)
cr <- catalog_results |>
mutate(Month = as.numeric(str_remove_all( str_extract(acquisitionDate, '-[0-9]{2}-'), '-'))) |>
filter(Month >= 5, Month <= 7) |> # we want to detect late laying snow packs
group_by(acquisitionDate) |> # only bother with tiles which have good coverage on that day! No need for random tiles.
mutate(
totalArea = sum(areaCoverage),
n = n()) |>
filter(n > 4 & totalArea >= 100) |>
mutate(
year = str_extract(acquisitionDate, '[0-9]{4}'),
doy = yday(acquisitionDate)
)
head(cr)
ggplot() +
geom_col(data = cr, aes(x = doy, y = n)) +
facet_wrap(~year)
View(cr)
ggplot() +
geom_point(data = cr, aes(x = doy, y = n)) +
facet_wrap(~year)
?n()
cr <- catalog_results |>
mutate(Month = as.numeric(str_remove_all( str_extract(acquisitionDate, '-[0-9]{2}-'), '-'))) |>
filter(Month >= 5, Month <= 7) |> # we want to detect late laying snow packs
group_by(acquisitionDate) |> # only bother with tiles which have good coverage on that day! No need for random tiles.
mutate(
totalArea = sum(areaCoverage),
n = n()) |>
filter(n > 4 & totalArea >= 100) |>
# NDSI cannot see through clouds, we will drop dates with
# very high cloud cover
mutate(
meanCloud = mean()
) |>
group_by(acquisitionDate) |>
mutate(
year = str_extract(acquisitionDate, '[0-9]{4}'),
doy = yday(acquisitionDate)
)
cr <- catalog_results |>
mutate(Month = as.numeric(str_remove_all( str_extract(acquisitionDate, '-[0-9]{2}-'), '-'))) |>
filter(Month >= 5, Month <= 7) |> # we want to detect late laying snow packs
group_by(acquisitionDate) |> # only bother with tiles which have good coverage on that day! No need for random tiles.
mutate(
totalArea = sum(areaCoverage),
n = n()) |>
filter(n > 4 & totalArea >= 100) |>
# NDSI cannot see through clouds, we will drop dates with
# very high cloud cover
mutate(
meanCloud = mean(tileCloudCover)
) |>
group_by(acquisitionDate) |>
mutate(
year = str_extract(acquisitionDate, '[0-9]{4}'),
doy = yday(acquisitionDate)
)
ggplot() +
geom_histogram(data = cr, aes(x = meanCloud))
cr <- catalog_results |>
mutate(Month = as.numeric(str_remove_all( str_extract(acquisitionDate, '-[0-9]{2}-'), '-'))) |>
filter(Month >= 5, Month <= 7) |> # we want to detect late laying snow packs
group_by(acquisitionDate) |> # only bother with tiles which have good coverage on that day! No need for random tiles.
mutate(
totalArea = sum(areaCoverage),
n = n()) |>
filter(n > 4 & totalArea >= 100) |>
# NDSI cannot see through clouds, we will drop dates with
# very high cloud cover
group_by(acquisitionDate) |>
mutate(
meanCloud = mean(tileCloudCover)
) |>
filter(meanCloud > 50) |
mutate(
year = str_extract(acquisitionDate, '[0-9]{4}'),
doy = yday(acquisitionDate)
)
cr <- catalog_results |>
mutate(Month = as.numeric(str_remove_all( str_extract(acquisitionDate, '-[0-9]{2}-'), '-'))) |>
filter(Month >= 5, Month <= 7) |> # we want to detect late laying snow packs
group_by(acquisitionDate) |> # only bother with tiles which have good coverage on that day! No need for random tiles.
mutate(
totalArea = sum(areaCoverage),
n = n()) |>
filter(n > 4 & totalArea >= 100) |>
# NDSI cannot see through clouds, we will drop dates with
# very high cloud cover
group_by(acquisitionDate) |>
mutate(
meanCloud = mean(tileCloudCover)
) |>
filter(meanCloud > 50) |>
mutate(
year = str_extract(acquisitionDate, '[0-9]{4}'),
doy = yday(acquisitionDate)
)
source("/media/steppe/hdd/EriogonumColoradenseTaxonomy/scripts/DownloadUpperGunnisonIndependentVariables.R", echo=TRUE)
ggplot() +
geom_histogram(data = cr, aes(x = meanCloud))
cr <- catalog_results |>
mutate(Month = as.numeric(str_remove_all( str_extract(acquisitionDate, '-[0-9]{2}-'), '-'))) |>
filter(Month >= 5, Month <= 7) |> # we want to detect late laying snow packs
group_by(acquisitionDate) |> # only bother with tiles which have good coverage on that day! No need for random tiles.
mutate(
totalArea = sum(areaCoverage),
n = n()) |>
filter(n > 4 & totalArea >= 100) |>
# NDSI cannot see through clouds, we will drop dates with
# very high cloud cover
group_by(acquisitionDate) |>
mutate(
meanCloud = mean(tileCloudCover)
) |>
filter(meanCloud <= 50) |>
mutate(
year = str_extract(acquisitionDate, '[0-9]{4}'),
doy = yday(acquisitionDate)
)
ggplot() +
geom_histogram(data = cr, aes(x = meanCloud))
ggplot() +
geom_point(data = cr, aes(x = doy, y = n)) +
facet_wrap(~year)
cr <- catalog_results |>
mutate(Month = as.numeric(str_remove_all( str_extract(acquisitionDate, '-[0-9]{2}-'), '-'))) |>
filter(Month >= 5, Month <= 7) |> # we want to detect late laying snow packs
group_by(acquisitionDate) |> # only bother with tiles which have good coverage on that day! No need for random tiles.
mutate(
totalArea = sum(areaCoverage),
n = n()) |>
filter(n > 4 & totalArea >= 100) |>
# NDSI cannot see through clouds, we will drop dates with
# very high cloud cover
group_by(acquisitionDate) |>
mutate(
meanCloud = mean(tileCloudCover)
) |>
filter(meanCloud <= 25) |>
mutate(
year = str_extract(acquisitionDate, '[0-9]{4}'),
doy = yday(acquisitionDate)
)
ggplot() +
geom_histogram(data = cr, aes(x = meanCloud))
ggplot() +
geom_point(data = cr, aes(x = doy, y = n)) +
facet_wrap(~year)
cr <- catalog_results |>
mutate(Month = as.numeric(str_remove_all( str_extract(acquisitionDate, '-[0-9]{2}-'), '-'))) |>
filter(Month >= 5, Month <= 7) |> # we want to detect late laying snow packs
group_by(acquisitionDate) |> # only bother with tiles which have good coverage on that day! No need for random tiles.
mutate(
totalArea = sum(areaCoverage),
n = n()) |>
filter(n > 4 & totalArea >= 100) |>
# NDSI cannot see through clouds, we will drop dates with
# very high cloud cover
group_by(acquisitionDate) |>
mutate(
meanCloud = mean(tileCloudCover)
) |>
filter(meanCloud <= 40) |>
mutate(
year = str_extract(acquisitionDate, '[0-9]{4}'),
doy = yday(acquisitionDate)
)
ggplot() +
geom_histogram(data = cr, aes(x = meanCloud))
ggplot() +
geom_point(data = cr, aes(x = doy, y = n)) +
facet_wrap(~year)
ggplot() +
geom_histogram(data = cr, aes(x = meanCloud))
ggplot() +
geom_point(data = cr, aes(x = doy, y = n)) +
facet_wrap(~year)
View(cr)
cr <- catalog_results |>
mutate(Month = as.numeric(str_remove_all( str_extract(acquisitionDate, '-[0-9]{2}-'), '-'))) |>
filter(Month >= 5, Month <= 7) |> # we want to detect late laying snow packs
group_by(acquisitionDate) |> # only bother with tiles which have good coverage on that day! No need for random tiles.
mutate(
totalArea = sum(areaCoverage),
n = n()) |>
filter(n > 4 & totalArea >= 100) |>
# NDSI cannot see through clouds, we will drop dates with
# very high cloud cover
group_by(acquisitionDate) |>
mutate(
meanCloud = mean(tileCloudCover)
) |>
filter(meanCloud <= 35) |>
# for visualizing whether we have AN OK cloud drop off time
mutate(
year = str_extract(acquisitionDate, '[0-9]{4}'),
doy = yday(acquisitionDate)
)
ggplot() +
geom_point(data = cr, aes(x = doy, y = n)) +
facet_wrap(~year)
'/media/steppe/hdd/Geospatial_data/Sentinel2EriogonumColoradense'
View(cr)
download.file('S2B_MSIL2A_20240729T174909_N0511_R141_T13SBC_20240729T214511.SAFE')
View(cr)
head(cr$sourceId)
ggplot() +
geom_point(data = cr, aes(x = doy, y = year))
