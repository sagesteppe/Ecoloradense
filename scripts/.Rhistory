st_transform(st_crs(revisits))
ground_truth <- filter(ground_truth, str_detect(Site, 'p', negate= T)) |>
select(-GlobalRandomID) |>
st_as_sf(coords = c(x = 'Longitude', y = 'Latitude'), crs = 4269) |>
st_transform(st_crs(revisits))
View(ground_truth)
View(revisits)
st_read('../data/GroundTruthPts/Revisits-cp.shp', quiet = T)
revisits <- st_read('../data/GroundTruthPts/Revisits-cp.shp', quiet = T) |>
select(UID) |>
mutate(UID = str_replace(UID, 'P', 'p')) #%>%
View(revisits)
View(ground_truth)
ground_truth <- read.csv('../data/GroundTruthing/Pts.csv') |>
mutate(
across(c('Dominant_Phen'), ~ na_if(., '')),
across(Presence_M:Presence_J, ~ replace_na(., 0)))
rand_pts_iter1 <- st_read('../data/GroundTruthPts/Iteration1-cp.shp', quiet = T) |>
select(UID) %>%
inner_join(., ground_truth, by = c('UID' = 'GlobalRandomID')) |>
mutate(Site = paste0('r-', UID)) |>
select(-Latitude, -Longitude, -UID)
ground_truth <- filter(ground_truth, is.na(GlobalRandomID)) # remove these random pts
revisits <- st_read('../data/GroundTruthPts/Revisits-cp.shp', quiet = T) |>
select(UID) |>
mutate(UID = str_replace(UID, 'P', 'p')) %>%
inner_join(., filter(ground_truth, str_detect(Site, 'p')), by = c('UID' = 'Site'))
ground_truth <- filter(ground_truth, str_detect(Site, 'p', negate= T)) |>
select(-GlobalRandomID) |>
st_as_sf(coords = c(x = 'Longitude', y = 'Latitude'), crs = 4269) |>
st_transform(st_crs(revisits))
View(revisits)
st_read('../data/GroundTruthPts/Revisits-cp.shp', quiet = T)
revisits <- st_read('../data/GroundTruthPts/Revisits-cp.shp', quiet = T) #|>
View(revisits)
revisits <- st_read('../data/GroundTruthPts/Revisits-cp.shp', quiet = T) |>
select(UID) |>
mutate(UID = str_replace(UID, 'P', 'p')) #%>%
ground_truth
revisits <- st_read('../data/GroundTruthPts/Revisits-cp.shp', quiet = T) |>
select(UID) |>
mutate(UID = str_replace(UID, 'P', 'p')) %>%
inner_join(., filter(ground_truth, str_detect(Site, 'p')), by = c('UID' = 'Site'))
ground_truth <- read.csv('../data/GroundTruthing/Pts.csv') |>
mutate(
across(c('Dominant_Phen'), ~ na_if(., '')),
across(Presence_M:Presence_J, ~ replace_na(., 0)))
rand_pts_iter1 <- st_read('../data/GroundTruthPts/Iteration1-cp.shp', quiet = T) |>
select(UID) %>%
inner_join(., ground_truth, by = c('UID' = 'GlobalRandomID')) |>
mutate(Site = paste0('r-', UID)) |>
select(-Latitude, -Longitude, -UID)
ground_truth <- filter(ground_truth, is.na(GlobalRandomID)) # remove these random pts
revisits <- st_read('../data/GroundTruthPts/Revisits-cp.shp', quiet = T) |>
select(UID) |>
mutate(UID = str_replace(UID, 'P', 'p')) %>%
inner_join(., filter(ground_truth, str_detect(Site, 'p')), by = c('UID' = 'Site'))
ground_truth <- filter(ground_truth, str_detect(Site, 'p', negate= T)) |>
select(-GlobalRandomID) |>
st_as_sf(coords = c(x = 'Longitude', y = 'Latitude'), crs = 4269) |>
st_transform(st_crs(revisits))
View(revisits)
revisits <- filter(revisits, !is.na(Latitude)) |>
st_drop_geometry() |>
st_as_sf(coords = c(x = 'Longitude', y = 'Latitude'), crs = 4269) |>
st_transform(st_crs(revisits)) %>%
bind_rows(., filter(revisits, is.na(Latitude))) |>
mutate(Site = UID) |>
select(-Latitude, -Longitude, -UID)
View(revisits)
ground_truth <- bind_rows(ground_truth, rand_pts_iter1, revisits) |>
select(-GlobalRandomID) %>%
mutate(Presence = ifelse(Presence_M > 0 | Presence_J > 0, 1, 0), .after = Presence_J)
st_write(ground_truth, '../data/GroundTruthing/QC.shp', append = F)
rm(rand_pts_iter1, revisits)
library(sf)
library(tidyverse)
library(terra)
source('functions.R')
set.seed(23)
ground_truth <- read.csv('../data/GroundTruthing/Pts.csv') |>
mutate(
across(c('Dominant_Phen'), ~ na_if(., '')),
across(Presence_M:Presence_J, ~ replace_na(., 0)))
rand_pts_iter1 <- st_read('../data/GroundTruthPts/Iteration1-cp.shp', quiet = T) |>
select(UID) %>%
inner_join(., ground_truth, by = c('UID' = 'GlobalRandomID')) |>
mutate(Site = paste0('r-', UID)) |>
select(-Latitude, -Longitude, -UID)
ground_truth <- filter(ground_truth, is.na(GlobalRandomID)) # remove these random pts
revisits <- st_read('../data/GroundTruthPts/Revisits-cp.shp', quiet = T) |>
select(UID) |>
mutate(UID = str_replace(UID, 'P', 'p')) %>%
inner_join(., filter(ground_truth, str_detect(Site, 'p')), by = c('UID' = 'Site'))
ground_truth <- filter(ground_truth, str_detect(Site, 'p', negate= T)) |>
select(-GlobalRandomID) |>
st_as_sf(coords = c(x = 'Longitude', y = 'Latitude'), crs = 4269) |>
st_transform(st_crs(revisits))
revisits <- filter(revisits, !is.na(Latitude)) |>
st_drop_geometry() |>
st_as_sf(coords = c(x = 'Longitude', y = 'Latitude'), crs = 4269) |>
st_transform(st_crs(revisits)) %>%
bind_rows(., filter(revisits, is.na(Latitude))) |>
mutate(Site = UID) |>
select(-Latitude, -Longitude, -UID)
ground_truth <- bind_rows(ground_truth, rand_pts_iter1, revisits) |>
select(-GlobalRandomID) %>%
mutate(Presence = ifelse(Presence_M > 0 | Presence_J > 0, 1, 0), .after = Presence_J)
st_write(ground_truth, '../data/GroundTruthing/QC.shp', append = F)
rm(rand_pts_iter1, revisits)
View(ground_truth)
filter(ground_truth, Presence == 1)
View(ground_truth)
gt_pres <- filter(ground_truth, Presence == 1)
gt_pres <- filter(ground_truth, Presence == 1) |>
dplyr::select(NAME = Collector_n_Number, Description = UNIQUEID) |>
sf::st_write(dsn = fname, driver = filetype,
delete_dsn = TRUE, quiet = T, append = F)
View(ground_truth)
View(gt_pres)
gt_pres <- filter(ground_truth, Presence == 1) |>
dplyr::select(NAME = OBJECT) |>
sf::st_write(dsn = '../data/GroundTruthing/Presences.shp', driver = '.kml',
delete_dsn = TRUE, quiet = T, append = F)
gt_pres <- filter(ground_truth, Presence == 1) |>
dplyr::select(NAME = OBJECT) |>
sf::st_write(dsn = '../data/GroundTruthing/Presences.shp', driver = 'kml',
quiet = T, append = F)
gt_pres <- filter(ground_truth, Presence == 1) |>
dplyr::select(NAME = OBJECT) |>
sf::st_write(dsn = '../data/GroundTruthing/Presences', driver = 'kml',
quiet = T, append = F)
gt_pres <- filter(ground_truth, Presence == 1) |>
dplyr::select(NAME = OBJECT) |>
sf::st_write(dsn = '../data/GroundTruthing/Presences', driver = 'kml',
quiet = T, append = F)
gt_pres <- filter(ground_truth, Presence == 1) |>
dplyr::select(NAME = OBJECT) |>
sf::st_write(dsn = '../data/GroundTruthing/Presences.kml', driver = 'kml',
quiet = T, append = F)
library(sf)
library(tidyverse)
library(terra)
source('functions.R')
set.seed(23)
ground_truth <- read.csv('../data/GroundTruthing/Pts.csv') |>
mutate(
across(c('Dominant_Phen'), ~ na_if(., '')),
across(Presence_M:Presence_J, ~ replace_na(., 0)))
rand_pts_iter1 <- st_read('../data/GroundTruthPts/Iteration1-cp.shp', quiet = T) |>
select(UID) %>%
inner_join(., ground_truth, by = c('UID' = 'GlobalRandomID')) |>
mutate(Site = paste0('r-', UID)) |>
select(-Latitude, -Longitude, -UID)
ground_truth <- filter(ground_truth, is.na(GlobalRandomID)) # remove these random pts
revisits <- st_read('../data/GroundTruthPts/Revisits-cp.shp', quiet = T) |>
select(UID) |>
mutate(UID = str_replace(UID, 'P', 'p')) %>%
inner_join(., filter(ground_truth, str_detect(Site, 'p')), by = c('UID' = 'Site'))
ground_truth <- filter(ground_truth, str_detect(Site, 'p', negate= T)) |>
select(-GlobalRandomID) |>
st_as_sf(coords = c(x = 'Longitude', y = 'Latitude'), crs = 4269) |>
st_transform(st_crs(revisits))
revisits <- filter(revisits, !is.na(Latitude)) |>
st_drop_geometry() |>
st_as_sf(coords = c(x = 'Longitude', y = 'Latitude'), crs = 4269) |>
st_transform(st_crs(revisits)) %>%
bind_rows(., filter(revisits, is.na(Latitude))) |>
mutate(Site = UID) |>
select(-Latitude, -Longitude, -UID)
ground_truth <- bind_rows(ground_truth, rand_pts_iter1, revisits) |>
select(-GlobalRandomID) %>%
mutate(Presence = ifelse(Presence_M > 0 | Presence_J > 0, 1, 0), .after = Presence_J)
st_write(ground_truth, '../data/GroundTruthing/QC.shp', append = F)
rm(rand_pts_iter1, revisits)
gt_pres <- filter(ground_truth, Presence == 1) |>
dplyr::select(NAME = OBJECT) |>
sf::st_write(dsn = '../data/GroundTruthing/Presences.kml', driver = 'kml',
quiet = T, append = F)
gt_pres <- filter(ground_truth, Presence == 1) |>
dplyr::select(NAME = OBJECT) |>
sf::st_write(dsn = '../data/GroundTruthing/Presences.kml', driver = 'kml',
quiet = T, append = F)
View(gt_pres)
comp_abs <- read.csv('../data/GroundTruthing/ComputerAbs.csv') |>
mutate(Presence_M = 0, Presence_J = 0, Presence = 0) |>
st_as_sf(coords = c(x = 'Longitude', y = 'Latitude'), crs = 4326) |>
st_transform(st_crs(ground_truth))
gt_pres <- filter(ground_truth, Presence == 1) |>
dplyr::select(NAME = OBJECT) |>
sf::st_write(dsn = '../data/GroundTruthing/Presences.kml', driver = 'kml',
quiet = T, append = F)
gt_abs <- filter(ground_truth, Presence == 0) |>
dplyr::select(NAME = OBJECT) |>
sf::st_write(dsn = '../data/GroundTruthing/Absences.kml', driver = 'kml',
quiet = T, append = F)
library(sf)
library(tidyverse)
library(terra)
source('functions.R')
set.seed(23)
ground_truth <- read.csv('../data/GroundTruthing/Pts.csv') |>
mutate(
across(c('Dominant_Phen'), ~ na_if(., '')),
across(Presence_M:Presence_J, ~ replace_na(., 0)))
rand_pts_iter1 <- st_read('../data/GroundTruthPts/Iteration1-cp.shp', quiet = T) |>
select(UID) %>%
inner_join(., ground_truth, by = c('UID' = 'GlobalRandomID')) |>
mutate(Site = paste0('r-', UID)) |>
select(-Latitude, -Longitude, -UID)
ground_truth <- filter(ground_truth, is.na(GlobalRandomID)) # remove these random pts
revisits <- st_read('../data/GroundTruthPts/Revisits-cp.shp', quiet = T) |>
select(UID) |>
mutate(UID = str_replace(UID, 'P', 'p')) %>%
inner_join(., filter(ground_truth, str_detect(Site, 'p')), by = c('UID' = 'Site'))
ground_truth <- filter(ground_truth, str_detect(Site, 'p', negate= T)) |>
select(-GlobalRandomID) |>
st_as_sf(coords = c(x = 'Longitude', y = 'Latitude'), crs = 4269) |>
st_transform(st_crs(revisits))
revisits <- filter(revisits, !is.na(Latitude)) |>
st_drop_geometry() |>
st_as_sf(coords = c(x = 'Longitude', y = 'Latitude'), crs = 4269) |>
st_transform(st_crs(revisits)) %>%
bind_rows(., filter(revisits, is.na(Latitude))) |>
mutate(Site = UID) |>
select(-Latitude, -Longitude, -UID)
ground_truth <- bind_rows(ground_truth, rand_pts_iter1, revisits) |>
select(-GlobalRandomID) %>%
mutate(Presence = ifelse(Presence_M > 0 | Presence_J > 0, 1, 0), .after = Presence_J)
st_write(ground_truth, '../data/GroundTruthing/QC.shp', append = F)
rm(rand_pts_iter1, revisits)
gt_pres <- filter(ground_truth, Presence == 1) |>
dplyr::select(NAME = OBJECT) |>
sf::st_write(dsn = '../data/GroundTruthing/Presences.kml', driver = 'kml',
quiet = T, append = F)
gt_abs <- filter(ground_truth, Presence == 0) |>
dplyr::select(NAME = OBJECT) |>
sf::st_write(dsn = '../data/GroundTruthing/Absences.kml', driver = 'kml',
quiet = T, append = F)
library(sf)
library(tidyverse)
library(terra)
source('functions.R')
set.seed(23)
ground_truth <- read.csv('../data/GroundTruthing/Pts.csv') |>
mutate(
across(c('Dominant_Phen'), ~ na_if(., '')),
across(Presence_M:Presence_J, ~ replace_na(., 0)))
rand_pts_iter1 <- st_read('../data/GroundTruthPts/Iteration1-cp.shp', quiet = T) |>
select(UID) %>%
inner_join(., ground_truth, by = c('UID' = 'GlobalRandomID')) |>
mutate(Site = paste0('r-', UID)) |>
select(-Latitude, -Longitude, -UID)
ground_truth <- filter(ground_truth, is.na(GlobalRandomID)) # remove these random pts
revisits <- st_read('../data/GroundTruthPts/Revisits-cp.shp', quiet = T) |>
select(UID) |>
mutate(UID = str_replace(UID, 'P', 'p')) %>%
inner_join(., filter(ground_truth, str_detect(Site, 'p')), by = c('UID' = 'Site'))
ground_truth <- filter(ground_truth, str_detect(Site, 'p', negate= T)) |>
select(-GlobalRandomID) |>
st_as_sf(coords = c(x = 'Longitude', y = 'Latitude'), crs = 4269) |>
st_transform(st_crs(revisits))
ground_truth <- filter(ground_truth, str_detect(Site, 'p', negate= T)) |>
select(-GlobalRandomID) |>
st_as_sf(coords = c(x = 'Longitude', y = 'Latitude'), crs = 4269) |>
st_transform(st_crs(revisits))
library(sf)
library(tidyverse)
library(terra)
source('functions.R')
set.seed(23)
ground_truth <- read.csv('../data/GroundTruthing/Pts.csv') |>
mutate(
across(c('Dominant_Phen'), ~ na_if(., '')),
across(Presence_M:Presence_J, ~ replace_na(., 0)))
rand_pts_iter1 <- st_read('../data/GroundTruthPts/Iteration1-cp.shp', quiet = T) |>
select(UID) %>%
inner_join(., ground_truth, by = c('UID' = 'GlobalRandomID')) |>
mutate(Site = paste0('r-', UID)) |>
select(-Latitude, -Longitude, -UID)
ground_truth <- filter(ground_truth, is.na(GlobalRandomID)) # remove these random pts
revisits <- st_read('../data/GroundTruthPts/Revisits-cp.shp', quiet = T) |>
select(UID) |>
mutate(UID = str_replace(UID, 'P', 'p')) %>%
inner_join(., filter(ground_truth, str_detect(Site, 'p')), by = c('UID' = 'Site'))
ground_truth <- filter(ground_truth, str_detect(Site, 'p', negate= T)) |>
select(-GlobalRandomID) |>
st_as_sf(coords = c(x = 'Longitude', y = 'Latitude'), crs = 4269) |>
st_transform(st_crs(revisits))
revisits <- filter(revisits, !is.na(Latitude)) |>
st_drop_geometry() |>
st_as_sf(coords = c(x = 'Longitude', y = 'Latitude'), crs = 4269) |>
st_transform(st_crs(revisits)) %>%
bind_rows(., filter(revisits, is.na(Latitude))) |>
mutate(Site = UID) |>
select(-Latitude, -Longitude, -UID)
comp_abs <- read.csv('../data/GroundTruthing/ComputerAbs.csv') |>
mutate(Presence_M = 0, Presence_J = 0, Presence = 0) |>
st_as_sf(coords = c(x = 'Longitude', y = 'Latitude'), crs = 4326) |>
st_transform(st_crs(ground_truth))
ab <- bind_rows(ground_truth, comp_abs) |>
st_write('../data/GroundTruthing/Iteration1Pts.shp', append = F)
library(spdep)
nn5 = knn2nb(knearneigh(ab, 8))
w = nb2listw(nn5, style="B")
joincount.test( as.factor(ab$Presence), w)
readRDS('../results/tables/3m-Iteration1.rds')
library(ranger)
model <- readRDS('../results/models/3m-Iteration1.rds')
importance(model)
modeller
source('functions.R')
View(modeller)
#' @param x input occurrence data
#' @param resolution list of paths to geodata at different resolutions.
#' @param iteration numeric, which iteration of modelling is being performed?
#' @param se_prediction boolean, whether to predict the SE surfaces or not, can add roughly
#' a week onto the prediction at 3m.
modeller <- function(x, resolution, iteration, se_prediction){
if(missing(se_prediction)){se_prediction <- FALSE}
rast_dat <- rastReader(paste0('dem_', resolution), p2proc)
cores <- parallel::detectCores()
df <- dplyr::bind_cols(
dplyr::select(x, Occurrence),
dplyr::select(terra::extract(rast_dat, x), -ID),
) |>
tidyr::drop_na() %>%
dplyr::mutate(
Occurrence = as.factor(Occurrence),
Pennock = as.factor(Pennock),
geomorphons = as.factor(geomorphons),
Longitude = unlist(purrr::map(.$geometry,1)),
Latitude  = unlist(purrr::map(.$geometry,2))) |>
sf::st_drop_geometry()
#######################         MODELLING           ##########################
# this is the fastest portion of this process. It will take at most a few minutes
# at any resolution, the goal of this paper wasn't really focused on comparing
# mutliple models of families nor messing with parameters, so we use Random Forest
# simply because they work very well with default settings, almost 'controlling'
# for stochasticity in this portion of the work.
# only rerun modelling if a saved .rds object doesn't exist.
if(file.exists(paste0('../results/models/', resolution, '-Iteration', iteration, '.rds'))){
rf_model <- readRDS(paste0('../results/models/', resolution, '-Iteration', iteration, '.rds'))
message('An exising model for this resolution and iteration already exists; reloading it now for projection')
} else {
# first we will perform boruta analysis, this will drop variables which have
# no relationship to the marks at the resolution under analysis.
# RandomForests do an excellent job of this - likely better than Boruta analysis...
# However what ends up happening is that many vars with very minor contributions to the
# model are kept. When it comes time to predict these models onto gridded surfaces
# these added terms (oftentimes requiring the re-reading of the rasters in a virtual context)
# make the prediction take AGES.
# We want to avoid everything taking ages.
BorutaRes <- Boruta::Boruta(Occurrence ~ ., data = df, num.threads = cores, doTrace = 0)
importance <- Boruta::attStats(BorutaRes)
rn <- rownames(importance[importance$decision %in% c('Confirmed'),])
important_vars <- Boruta::getSelectedAttributes(BorutaRes, withTentative = F)
df <- dplyr::select(df, dplyr::all_of(c('Occurrence', 'Longitude', 'Latitude', important_vars)))
rm(BorutaRes, importance, rn, important_vars)
# split the input data into both an explicit train and test data set.
TrainIndex <- caret::createDataPartition(
df$Occurrence, p = .8, list = FALSE, times = 1)
Train <- df[ TrainIndex,]; Test <- df[-TrainIndex,]
# perform the random forest modelling using default settings.
rf_model <- ranger::ranger(
Occurrence ~ ., data = Train, probability = T, keep.inbag = TRUE,
importance = 'permutation')
# save the model
saveRDS(rf_model,
file = paste0('../results/models/', resolution, '-Iteration', iteration, '.rds'))
# save the confusion matrix
predictions <- predict(rf_model, Test, type = 'se', se.method = 'infjack', probability=TRUE, importance = TRUE)
predictions$binary <- as.factor(if_else(predictions$predictions[,2] <= 0.49, 0, 1))
cmRestrat <- caret::confusionMatrix(predictions$binary, Test$Occurrence,
prevalence = 1, mode = 'everything')
saveRDS(cmRestrat,
file = paste0('../results/tables/', resolution, '-Iteration', iteration, '.rds'))
# we will also save the Pr-AUC as some folks find it a useful metric for class unbalanced
# data sets.
df_prauc <- data.frame(
truth = Test$Occurrence,
Class1 = predictions$predictions[,1]
)
yardstick::pr_auc(df_prauc, truth, Class1) |>
mutate(resolution = resolution, iteration = iteration) |>
write.csv(
paste0('../results/tables/', resolution, '-Iteration', iteration, '.csv'),
row.names = F)
rm(df, df_prauc, TrainIndex, Train, Test, predictions, cmRestrat, Longitude, Latitude)
}
pout <- '../results/suitability_maps'
rm(df)
###################      PREDICT ONTO SURFACE        #########################
# this prediction is generally straightforward, it doesn't take an obscene
# amount of RAM and can happen relatively quickly, just overnight for the
# higher resolution scenarios.
pr <- function(...) predict(..., type = 'response', num.threads = 1)$predictions
if(resolution %in% c('3arc', '1arc', '1-3arc', '3m')){ntile = 1} else
if(resolution == '1m'){ntile = 4}
if(ntile > 1){
tile_path_4pr <- file.path(pout, paste0('tilesPR', '_', resolution))
if(file.exists(tile_path_4pr)){
message('Tiles already created for this resolution, skipping to prediction!\n')
} else {
dir.create(tile_path_4pr, showWarnings = F); message('Making tiles for prediction')
template <- rast(nrows = ntile, ncols = ntile, extent = ext(rast_dat), crs = crs(rast_dat))
terra::makeTiles(rast_dat, template, filename = file.path(tile_path_4pr, "tile_.tif"))
rm(template)
}
tiles <- file.path(pout, 'tilesPR', list.files(file.path(pout, 'tilesPR')))
pr_tile_path <- file.path(pout, paste0('pr_tiles', '_', resolution, iteration))
dir.create(pr_tile_path, showWarnings = F)
message('Writing Predicted Probability to Raster using tiles - this while take some time')
pb <- txtProgressBar(
min = 0,  max = length(tiles), style = 3, width = 50, char = "+")
for (i in seq_along(tiles)){
terra::predict(
rast(tiles[i]), rf_model, f = pr,
filename = file.path(pr_tile_path, paste0(i, '.tif')),
overwrite = T, na.rm=TRUE)
setTxtProgressBar(pb, i)
gc(verbose = FALSE)
}
close(pb)
mos <- terra::mosaic(sprc(
file.path(pr_tile_path, list.files(pr_tile_path))
), fun = 'mean')
writeRaster(
mos[[2]],
wopt = c(names = 'Probability'),
filename = file.path(pout, paste0(resolution, '-Iteration', iteration, '-Pr.tif')))
rm(mos)
unlink(file.path(pout, 'pr_tiles')) # can remove the tiles we used for the probability surface.
} else { # in these cases, we only need to use a single tile for prediction, we can
# just use the existing virtual raster to do this.
if(!file.exists(file.path(pout, paste0(resolution, '-Iteration', iteration, '-Pr.tif')))){
message('Writing Predicted Probability to Raster')
terra::predict( # rasters, skip straight to modelling.
cores = 1, f = pr,
rast_dat, rf_model, cpkgs = "ranger",
filename = file.path(pout, paste0(resolution, '-IterationCoarse', iteration, '.tif')),
wopt = c(names = 'predicted_suitability'), na.rm=TRUE,
overwrite = T)
writeRaster( # we wrote a raster with both predicted class probabilities onto it.
# we don't want both, we are going to 'rewrite' the raster so only one class remains.
rast(file.path(pout, paste0(resolution, '-IterationCoarse', iteration, '.tif')))[[2]],
file.path(pout, paste0(resolution, '-Iteration', iteration, '-Pr.tif')),
overwrite = T
)
file.remove(file.path(pout, paste0(resolution, '-IterationCoarse', iteration, '.tif')))
} else {'Predicted Probability Raster already exists - skipping.'}
}
unlink(file.path(pout, 'pr_tiles'))
gc(verbose = FALSE)
###############      STANDARD ERROR PREDICTION        ########################
# the SE predictions are absurdly memory hungry, We will create 'tiles' to
# predict onto, and then combine them once the predictions are complete
# Note I use the term SE here, because it's what the R package uses, however,
# upon further reading what they are actually calculating is a Confidence
# interval - so great naming... https://github.com/imbs-hl/ranger/issues/136
if(se_prediction == TRUE){
tile_path_4se <- file.path(pout, paste0(resolution, 'TilesSE'))
final_se_path <- file.path(pout, paste0(resolution, 'SETiles'))
# it seems the tiles pretty much need to be under 200MB or so for safe CI prediction???
if(resolution == '3arc'){ntile = 2} else # 4 tiles
if(resolution == '1arc'){ntile = 6} else # 36 tiles Needed # earlier iteration with 16 FAILED # iter w/ 25 failed on tile 18...
if(resolution == '1-3arc'){ntile = 16}  # 144 /121/81 failed - follow under 200mb rule.
if(resolution == '3m'){
'Confidence Intervals cannot be produced for data of these size;
it would require over 2k tiles and 1 week of compute'}  else {
# don't create the tiles if they already exist.
if(exists(tile_path_4se)){
message('Tiles for SE exist at this resolution, skipping to predict.')} else {
message('Making tiles for prediction of standard errors')
dir.create(tile_path_4se, showWarnings = F)
dir.create(final_se_path, showWarnings = F)
template <- rast(nrows = ntile, ncols = ntile, extent = ext(rast_dat), crs = crs(rast_dat))
terra::makeTiles(rast_dat, template, filename = file.path(tile_path_4se, "tile_.tif"))
rm(template)
}
tiles <- file.path(tile_path_4se, list.files(tile_path_4se))
se <- function(...) predict(..., type = 'se', se.method = 'infjack',
predict.all = FALSE,
probability = TRUE, num.threads = cores/4)$se
# # predict the standard error onto the tiles.
# create and initialize progress bar
message('Predicting SE to tiles; this may take a really long time')
pb <- txtProgressBar(
min = 0,  max = length(tiles), style = 3, width = 50, char = "+")
for (i in seq_along(tiles)){
if(!file.exists(file.path(final_se_path, paste0('SE', i, '.tif')))){ # in case of crash, pick up where left off.
terra::predict(
rast(tiles[i]), rf_model, f = se,
filename = file.path(final_se_path, paste0('SE', i, '.tif')),
overwrite = T, na.rm=TRUE)
gc(verbose = FALSE)}
setTxtProgressBar(pb, i)
}
close(pb)
mos <- terra::mosaic(sprc(
file.path(final_se_path, list.files(final_se_path))
), fun = 'mean')
writeRaster(
mos[[2]],
wopt = c(names = 'standardError'),
filename = file.path(pout, paste0(resolution, '-Iteration', iteration, '-SE.tif')),
overwrite = T)
gc(verbose = FALSE)
}
unlink(final_se_path)
}
}
