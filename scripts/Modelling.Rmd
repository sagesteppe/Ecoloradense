---
title: "Modelling Eriogonum coloradense Presence and Abundance"
author: "steppe"
output: html_document
---

```{r, warning = F, message = F}
library(sf)
library(tidyverse)
library(terra)
library(caret)
library(bonsai)
library(parsnip)
library(ranger)
library(lightgbm)
library(future)
library(dials)
library(finetune)
source('functions.R')
set.seed(23)
```

```{r}
p <- '../data/Data4modelling'
f <- file.path(p, list.files(p))
```

Model presence for iteration 0, that is historic records only. 

Model presence for iteration 1, both the historic and 2024 ground truth data. 
```{r, eval = F}

abs <- st_read('../data/Data4modelling/iter1-pa.gpkg')
m30 <- sf::st_read("../data/Data4modelling/10m-presence-iter1.gpkg") %>% 
  rename(Occurrence = Presenc) |>
  sf::st_as_sf() 
### we know that 1:1 absence to presence is far too low when including the 'local'
# absences. 
m30 <- bind_rows(m30, abs)
m30 <- filter(m30, st_is(m30, "POINT")) |>
  select(Occurrence)

distOrder_PAratio_simulator(
  x = m30, distOrder = 0, PAratio = 3.0,
  resolution = 10, iteration = 1, se_prediction = FALSE,
  train_split = 0.9, p2proc = '../data/spatial/processed'
  )

```

# playing with count prediction 

```{r Partition data and clean for modelling}

p <- '/media/steppe/hdd/EriogonumColoradenseTaxonomy/results/suitability_maps'
f <- list.files(p, pattern = '-Pr.tif')

#' fit xgboosted models to predict plant count per space density. 
#' @param f a vector of predicted suitable habitat rasters to use for input. 
wrapper <- function(x){
  
  res <- gsub('-I.*$', '', x)
  res_string <- switch(res,
                      "3m" = "3m",
                      "1-3arc" = "10m",
                      "1arc" = "30m",
                      "3arc" = "90m",
                      stop("Input to `res` invalid. Need be one of: 3, 10, 30, 90")
  )
  
  ct <- sf::st_read(
    file.path('..', 'data', 'Data4modelling', paste0(res_string, '-count-iter1.gpkg')
              ), quiet = TRUE
    ) |>
  dplyr::select(Prsnc_M, Prsnc_J, Lctn_bb)
  
  p2proc = '../data/spatial/processed'
  rast_dat <- rastReader(paste0('dem_', res), p2proc) 

  r <- terra::rast(file.path('..', 'results', 'suitability_maps', x))
  df <- dplyr::bind_cols(
   ct, 
    dplyr::select(terra::extract(rast_dat, ct), -ID), 
    Pr.SuitHab = terra::extract(r, ct)$X1
  ) |> 
    filter(Lctn_bb != 'PABA') |>
    mutate(Prsnc_All = Prsnc_J + Prsnc_M, .before = 1) |>
    tidyr::drop_na() |>
    select(-Prsnc_J, -Prsnc_M)
  
  densityModeller(df, fp = '../results/CountModels', bn = gsub('DO.*$', '', x))
  
}

lapply(f, wrapper)

```

Modelling count data has not been very successful, nor did the field work really develop any strong insights on what drives the abundance of the plants. 
Rather the abundance seemed random within populations, and between - with the exception of Cocheotopa where plants were much smaller and incredibly more abundant than elsewhere. 

The null hypothesis for estimating population sizes will be the use of the arithmetic mean per populations. 


The use of kriging interpolation, where we simple smooth averages out between the plots, will be our null hypothesis for any spatial estimates of population size. 

While random forests are relatively robust against the presence of uninformative features, gradient boosting methods are less so.
Here we will use recursive feature elimination to drop some variables from our data set. 

As we can see from the table above, fewer variables work considerably better. 
We reduce the mean absolute error by nearly half a plant per quadrant! 

Tweedie needs to be allowed to explore the hyperparameters more than poisson. 


```{r}
densityModeller(df, fp = '../results/CountModels', bn = '1arc-Iteration1-PA1:3.6')
```


